{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import dysts.flows as flows\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from panda.utils.data_utils import (\n",
    "    get_system_filepaths,\n",
    "    load_trajectory_from_arrow,\n",
    ")\n",
    "from panda.utils.plot_utils import plot_trajs_multivariate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils and Data Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = os.environ.get(\"WORK\", \"\")\n",
    "DATA_DIR = os.path.join(WORK_DIR, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_split_name = \"improved/final_skew40\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_names_lst = [f\"{main_split_name}/train\", f\"{main_split_name}/train_z5_z10\"]\n",
    "split_names_lst = [\n",
    "    f\"{main_split_name}/test_zeroshot\",\n",
    "    f\"{main_split_name}/test_zeroshot_z5_z10\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_paths_lst = [os.path.join(DATA_DIR, split_name) for split_name in split_names_lst]\n",
    "print(f\"split paths: {split_paths_lst}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirs = []\n",
    "for split_path in split_paths_lst:\n",
    "    subdirs.extend([d for d in os.listdir(split_path) if os.path.isdir(os.path.join(split_path, d))])\n",
    "print(f\"Found {len(subdirs)} subdirectories in {split_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_subdirs = list(set(subdirs))\n",
    "print(f\"Found {len(unique_subdirs)} unique subdirectories in {split_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir_samples_dict = defaultdict(list)\n",
    "for subdir in unique_subdirs:\n",
    "    for split_path in split_paths_lst:\n",
    "        if subdir in os.listdir(split_path):\n",
    "            subdir_samples_dict[subdir].extend(\n",
    "                [int(filename.split(\"_T-4096.arrow\")[0]) for filename in os.listdir(os.path.join(split_path, subdir))]\n",
    "            )\n",
    "            subdir_samples_dict[subdir].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(subdir_samples_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Filtered Params Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_json_path_train = os.path.join(DATA_DIR, f\"{main_split_name}/parameters/train/successes.json\")\n",
    "parameters_json_path_test = os.path.join(DATA_DIR, f\"{main_split_name}/parameters/test/successes.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_params_dict_train = json.load(open(parameters_json_path_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_params_dict_test = json.load(open(parameters_json_path_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Found {len(saved_params_dict_train.keys())} systems with successful param perts in train\")\n",
    "print(f\"Found {len(saved_params_dict_test.keys())} systems with successful param perts in test\")\n",
    "print(\n",
    "    f\"... for a total of {len(saved_params_dict_train.keys()) + len(saved_params_dict_test.keys())} systems with successful param perts\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(saved_params_dict_train.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_subdir_samples_dict = {}\n",
    "filtered_params_dict = {}\n",
    "total_systems = 0\n",
    "\n",
    "zs_counter = 0\n",
    "for i, (system_name, samples_lst) in tqdm(enumerate(subdir_samples_dict.items()), desc=\"Checking all subdirs...\"):\n",
    "    # print(f\"System: {system_name} has {len(samples_lst)} samples\")\n",
    "    system_param_dict = {}\n",
    "\n",
    "    # system_name must be in either saved_params_dict_train XOR saved_params_dict_test\n",
    "    if system_name in saved_params_dict_train:\n",
    "        system_param_dict = saved_params_dict_train[system_name]\n",
    "    elif system_name in saved_params_dict_test:\n",
    "        system_param_dict = saved_params_dict_test[system_name]\n",
    "    else:\n",
    "        zs_counter += 1\n",
    "        continue\n",
    "\n",
    "    # print(f\"system_param_dict for {system_name}: {system_param_dict}\")\n",
    "\n",
    "    samples_lst_in_system_param_dict = [d[\"sample_idx\"] for d in system_param_dict]\n",
    "    filtered_samples_lst = list(set(samples_lst) & set(samples_lst_in_system_param_dict))\n",
    "\n",
    "    if len(filtered_samples_lst) == 0:\n",
    "        continue\n",
    "\n",
    "    total_systems += len(filtered_samples_lst)\n",
    "    # Get the dicts corresponding to the filtered sample indices\n",
    "    filtered_params_dict[system_name] = [\n",
    "        param_dict for param_dict in system_param_dict if param_dict[\"sample_idx\"] in filtered_samples_lst\n",
    "    ]\n",
    "    filtered_subdir_samples_dict[system_name] = filtered_samples_lst\n",
    "\n",
    "print(\"zs_counter: \", zs_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_subdir_samples_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Filtered Params Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "output_dir = \"../../outputs\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Save the filtered parameters dictionary to a JSON file\n",
    "# output_path = os.path.join(output_dir, \"filtered_params_dict.json\")\n",
    "output_path = os.path.join(output_dir, \"filtered_params_dict_test_zeroshot.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: uncomment the cell below to save the filtered params dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to lists for JSON serialization\n",
    "def convert_numpy_to_list(obj):\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_numpy_to_list(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_numpy_to_list(item) for item in obj]\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "\n",
    "# Create a serializable version of the dictionary\n",
    "serializable_params_dict = {}\n",
    "for system_name, param_dicts in filtered_params_dict.items():\n",
    "    serializable_params_dict[system_name] = [convert_numpy_to_list(param_dict) for param_dict in param_dicts]\n",
    "\n",
    "# Save to JSON file\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(serializable_params_dict, f, indent=2)\n",
    "\n",
    "print(f\"Saved filtered parameters to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Param Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_params_dicts = json.load(open(output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reloaded_params_dicts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_systems_reloaded = sum([len(v) for v in reloaded_params_dicts.values()])\n",
    "print(f\"tot_systems_reloaded: {tot_systems_reloaded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_system_name = \"LorenzBounded_YuWang2\"\n",
    "test_system_name = \"HastingsPowell_LuChenCheng\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_test_params = reloaded_params_dicts[test_system_name][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_test_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_param_dicts = filtered_params_dict[test_system_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = test_param_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key_name in test_params.keys():\n",
    "    if key_name == \"ic\":\n",
    "        assert np.allclose(reloaded_test_params[\"ic\"], test_params[\"ic\"])\n",
    "    elif key_name == \"coupling_map\":\n",
    "        continue\n",
    "    else:\n",
    "        assert reloaded_test_params[key_name] == test_params[key_name]\n",
    "    print(key_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Trajectories. NOTE: More testing done in `test_reloaded_params.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from panda.utils import init_skew_system_from_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_skew = \"_\" in test_system_name\n",
    "if is_skew:\n",
    "    driver_name, response_name = test_system_name.split(\"_\")\n",
    "    sys = init_skew_system_from_params(driver_name, response_name, reloaded_test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set initial condition\n",
    "sys.ic = np.array(reloaded_test_params[\"ic\"])\n",
    "print(sys.ic)\n",
    "\n",
    "if not sys.has_jacobian():\n",
    "    print(f\"Jacobian not implemented for {test_system_name}\")\n",
    "\n",
    "num_timesteps = 4311\n",
    "num_periods = 40\n",
    "\n",
    "ts, traj = sys.make_trajectory(\n",
    "    num_timesteps,\n",
    "    pts_per_period=num_timesteps // num_periods,\n",
    "    return_times=True,\n",
    "    atol=1e-10,\n",
    "    rtol=1e-8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transient_frac = 0.05\n",
    "transient_length = int(transient_frac * num_timesteps)\n",
    "trajectory = traj[None, transient_length:, :]\n",
    "print(trajectory.shape)\n",
    "trajectory_to_plot = trajectory.transpose(0, 2, 1)\n",
    "driver_coords = trajectory_to_plot[:, : sys.driver_dim, :]\n",
    "response_coords = trajectory_to_plot[:, sys.driver_dim :, :]\n",
    "for name, coords in [\n",
    "    (\"driver\", driver_coords),\n",
    "    (\"response\", response_coords),\n",
    "]:\n",
    "    plot_trajs_multivariate(\n",
    "        coords,\n",
    "        save_dir=\"tests/figs\",\n",
    "        plot_name=f\"reconstructed_{test_system_name}_{name}\",\n",
    "        standardize=True,\n",
    "        plot_projections=False,\n",
    "        show_plot=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 0\n",
    "\n",
    "filepaths = get_system_filepaths(test_system_name, DATA_DIR, split_names_lst[0])[sample_idx : sample_idx + 1]\n",
    "print(f\"{test_system_name} filepaths: \", filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_coords(\n",
    "    filepaths: list[Path], one_dim_target: bool = False, num_samples: int | None = None\n",
    ") -> np.ndarray:\n",
    "    dyst_coords_samples = []\n",
    "    for filepath in filepaths:\n",
    "        if num_samples is not None and len(dyst_coords_samples) >= num_samples:\n",
    "            break\n",
    "        dyst_coords, _ = load_trajectory_from_arrow(filepath, one_dim_target)\n",
    "        dyst_coords_samples.append(dyst_coords)\n",
    "\n",
    "    dyst_coords_samples = np.array(dyst_coords_samples)  # type: ignore\n",
    "    return dyst_coords_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyst_coords_samples = accumulate_coords(filepaths, one_dim_target=False)\n",
    "coords_dim = dyst_coords_samples.shape[1]\n",
    "print(f\"{test_system_name} coords_dim: \", coords_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the trajectories\n",
    "plot_name = f\"{test_system_name}\"\n",
    "\n",
    "is_skew = \"_\" in test_system_name\n",
    "if is_skew and coords_dim >= 6:  # hacky check\n",
    "    driver_name, _ = test_system_name.split(\"_\")\n",
    "    driver_dim = getattr(flows, driver_name)().dimension\n",
    "    driver_coords = dyst_coords_samples[:, :driver_dim, :]\n",
    "    response_coords = dyst_coords_samples[:, driver_dim:, :]\n",
    "    for name, coords in [\n",
    "        (\"driver\", driver_coords),\n",
    "        (\"response\", response_coords),\n",
    "    ]:\n",
    "        plot_trajs_multivariate(\n",
    "            coords,\n",
    "            save_dir=\"tests/figs\",\n",
    "            plot_name=f\"{plot_name}_{name}\",\n",
    "            samples_subset=None,\n",
    "            standardize=True,\n",
    "            plot_projections=False,\n",
    "            show_plot=True,\n",
    "        )\n",
    "else:\n",
    "    plot_trajs_multivariate(\n",
    "        dyst_coords_samples,\n",
    "        save_dir=\"tests/figs\",\n",
    "        plot_name=plot_name,\n",
    "        samples_subset=None,\n",
    "        standardize=True,\n",
    "        plot_projections=False,\n",
    "        show_plot=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
