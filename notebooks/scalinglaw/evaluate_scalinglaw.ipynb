{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from typing import Literal\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from panda.utils.plot_utils import apply_custom_style, make_box_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_custom_style(\"../../config/plotting.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_save_dir = os.path.join(\"../../figures\", \"eval_metrics\")\n",
    "os.makedirs(figs_save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = os.getenv(\"WORK\", \"\")\n",
    "DATA_DIR = os.path.join(WORK_DIR, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalinglaw_splits = [2**i for i in range(0, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalinglaw_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_split = \"final_skew40/test_zeroshot\"\n",
    "data_split = \"test_zeroshot\"\n",
    "\n",
    "run_names_chattn = {\n",
    "    # \"ic1\": \"pft_chattn_noembed_pretrained_correct-0\",\n",
    "    \"ic1\": \"pft_chattn_mlm_sys20k_ic1-0\",\n",
    "    \"ic2\": \"pft_chattn_mlm_sys10490_ic2-0\",\n",
    "    \"ic4\": \"pft_chattn_mlm_sys5245_ic4-0\",\n",
    "    \"ic8\": \"pft_chattn_mlm_sys2623_ic8-0\",\n",
    "    \"ic16\": \"pft_chattn_mlm_sys1312_ic16-0\",\n",
    "    \"ic32\": \"pft_chattn_mlm_sys656_ic32-0\",\n",
    "    \"ic64\": \"pft_chattn_mlm_sys328_ic64-0\",\n",
    "    \"ic128\": \"pft_chattn_mlm_sys164_ic128-0\",\n",
    "}\n",
    "\n",
    "run_metrics_dirs_all_groups = {\n",
    "    \"chattn\": {\n",
    "        run_abbrv: os.path.join(\n",
    "            WORK_DIR,\n",
    "            \"eval_results\",\n",
    "            \"patchtst\",\n",
    "            run_name,\n",
    "            data_split,\n",
    "        )\n",
    "        for run_abbrv, run_name in run_names_chattn.items()\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_metrics_dirs_all_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_all = defaultdict(lambda: defaultdict(dict))\n",
    "for run_group, run_metrics_dir_dict in run_metrics_dirs_all_groups.items():\n",
    "    print(f\"Run group: {run_group}\")\n",
    "    for run_abbrv, run_metrics_dir in run_metrics_dir_dict.items():\n",
    "        if not os.path.exists(run_metrics_dir):\n",
    "            print(f\"Run metrics directory does not exist for {run_abbrv}: {run_metrics_dir}\")\n",
    "            continue\n",
    "        run_abbrv = str(run_abbrv)\n",
    "        print(f\"{run_abbrv}: {run_metrics_dir}\")\n",
    "        for file in sorted(\n",
    "            os.listdir(run_metrics_dir),\n",
    "            key=lambda x: int(x.split(\"_pred\")[1].split(\".csv\")[0]),\n",
    "        ):\n",
    "            if file.endswith(\".csv\"):\n",
    "                prediction_length = int(file.split(\"_pred\")[1].split(\".csv\")[0])\n",
    "                # print(f\"Prediction length: {prediction_length} for {run_abbrv}\")\n",
    "                with open(os.path.join(run_metrics_dir, file)) as f:\n",
    "                    metrics = pd.read_csv(f).to_dict()\n",
    "                    metrics_all[run_group][run_abbrv][prediction_length] = metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_all.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrolled_metrics_all_groups = defaultdict(lambda: defaultdict(dict))\n",
    "for run_group, all_metrics_of_run_group in metrics_all.items():\n",
    "    # print(run_group)\n",
    "    for run_abbrv, all_metrics_of_run_abbrv in all_metrics_of_run_group.items():\n",
    "        # print(run_abbrv)\n",
    "        for run_name, metrics in all_metrics_of_run_abbrv.items():\n",
    "            # print(run_name)\n",
    "            systems = metrics.pop(\"system\")\n",
    "            metrics_unrolled = {k: list(v.values()) for k, v in metrics.items()}\n",
    "            # print(metrics_unrolled.keys())\n",
    "            unrolled_metrics_all_groups[run_group][run_abbrv][run_name] = metrics_unrolled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrolled_metrics_all_combined = {\n",
    "    **unrolled_metrics_all_groups[\"chattn\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_metrics_dict(unrolled_metrics, metric_name):\n",
    "    summary_metrics_dict = defaultdict(dict)\n",
    "    for model_name, metrics_dict in unrolled_metrics.items():\n",
    "        prediction_lengths = list(metrics_dict.keys())\n",
    "        summary_metrics_dict[model_name][\"prediction_lengths\"] = prediction_lengths\n",
    "        means = []\n",
    "        medians = []\n",
    "        stds = []\n",
    "        for prediction_length in prediction_lengths:\n",
    "            metric_val = metrics_dict[prediction_length][metric_name]\n",
    "            means.append(np.nanmean(metric_val))\n",
    "            medians.append(np.nanmedian(metric_val))\n",
    "            stds.append(np.nanstd(metric_val))\n",
    "        summary_metrics_dict[model_name][\"means\"] = means\n",
    "        summary_metrics_dict[model_name][\"medians\"] = medians\n",
    "        summary_metrics_dict[model_name][\"stds\"] = stds\n",
    "    return summary_metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_by_prediction_length(metrics_dict, metric_name, show_std_envelope=False):\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    for model_name, metrics in metrics_dict.items():\n",
    "        plt.plot(\n",
    "            metrics[\"prediction_lengths\"],\n",
    "            metrics[\"medians\"],\n",
    "            marker=\"o\",\n",
    "            label=model_name,\n",
    "        )\n",
    "        std_envelope = np.array(metrics[\"stds\"])\n",
    "        if show_std_envelope:\n",
    "            plt.fill_between(\n",
    "                metrics[\"prediction_lengths\"],\n",
    "                metrics[\"means\"] - std_envelope,\n",
    "                metrics[\"means\"] + std_envelope,\n",
    "                alpha=0.2,\n",
    "            )\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.xlabel(\"Prediction Length\")\n",
    "    plt.title(metric_name, fontweight=\"bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_metrics_dirs_all_groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names_chosen = [\n",
    "    \"mse\",\n",
    "    \"mae\",\n",
    "    \"smape\",\n",
    "    \"spearman\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_dict = defaultdict(dict)\n",
    "\n",
    "for run_group in run_metrics_dirs_all_groups.keys():\n",
    "    all_metrics_dict[run_group] = {\n",
    "        metrics_name: get_summary_metrics_dict(unrolled_metrics_all_groups[run_group], metrics_name)\n",
    "        for metrics_name in metric_names_chosen\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_colors = plt.cm.tab10.colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_dict[\"chattn\"][\"mse\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrolled_metrics_all_groups[\"chattn\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrolled_metrics_all_combined.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = len(unrolled_metrics_all_combined)\n",
    "print(n_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_colors = plt.cm.Blues(np.linspace(1.0, 0.1, n_runs)).tolist()\n",
    "print(len(bar_colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pred_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrolled_metrics_all_combined.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrolled_metrics_all_combined[\"ic2\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrolled_metrics_all_combined[\"ic2\"][128].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_to_n_systems = {\n",
    "    \"ic1\": 20979,\n",
    "    \"ic2\": 10490,\n",
    "    \"ic4\": 5245,\n",
    "    \"ic8\": 2623,\n",
    "    \"ic16\": 1312,\n",
    "    \"ic32\": 656,\n",
    "    \"ic64\": 328,\n",
    "    \"ic128\": 164,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scaling_plot(\n",
    "    unrolled_metrics: dict,\n",
    "    prediction_length: int = 128,\n",
    "    metric_to_plot: str = \"smape\",\n",
    "    stat_to_plot: Literal[\"median\", \"mean\"] = \"median\",\n",
    "    colormap: str = \"Blues\",\n",
    "    legend_kwargs: dict = {},\n",
    "    figsize: tuple = (4, 4),\n",
    "    save_path: str | None = None,\n",
    "    use_inv_spearman: bool = True,\n",
    "    show_legend: bool = True,\n",
    "    title: str | None = None,\n",
    ") -> None:\n",
    "    if metric_to_plot == \"smape\":\n",
    "        metric_to_plot_title = \"sMAPE\"\n",
    "    elif metric_to_plot == \"spearman\" and use_inv_spearman:\n",
    "        metric_to_plot_title = \"1 - Spearman\"\n",
    "    else:\n",
    "        metric_to_plot_title = metric_to_plot.upper()\n",
    "\n",
    "    metric_at_predlength = defaultdict(list)\n",
    "    for ic_split, metrics_by_predlength_dict in unrolled_metrics.items():\n",
    "        n_systems = ic_to_n_systems[ic_split]\n",
    "        metric_at_predlength[n_systems] = metrics_by_predlength_dict[prediction_length][metric_to_plot]\n",
    "    # sort metric_at_predlength by n_systems\n",
    "    metric_at_predlength = dict(sorted(metric_at_predlength.items()))\n",
    "    # make line plot of medians of metric_at_predlength\n",
    "    colors = plt.cm.get_cmap(colormap)(np.linspace(0, 1.0, len(metric_at_predlength)))\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i, (n_systems, metric_vals) in enumerate(metric_at_predlength.items()):\n",
    "        metric_vals = np.array(metric_vals)\n",
    "        # get rid of nan values\n",
    "        metric_vals = metric_vals[~np.isnan(metric_vals)]\n",
    "        if metric_to_plot == \"spearman\" and use_inv_spearman:\n",
    "            metric_vals = 1 - metric_vals\n",
    "\n",
    "        if stat_to_plot == \"median\":\n",
    "            median_vals = np.median(metric_vals)\n",
    "            # Create a custom boxplot similar to make_box_plot function\n",
    "            box_percentile_range = (40, 60)\n",
    "            whisker_percentile_range = (25, 75)\n",
    "            box_width = 0.5 * n_systems  # NOTE: this assumes x-axis is log scale\n",
    "            alpha_val = 0.8\n",
    "\n",
    "            # Calculate the percentiles\n",
    "            lower_box, upper_box = np.percentile(metric_vals, box_percentile_range)\n",
    "            lower_whisker, upper_whisker = np.percentile(metric_vals, whisker_percentile_range)\n",
    "\n",
    "            # Box width and spacing parameters\n",
    "            box_half_width = box_width / 2\n",
    "            whisker_cap_width = box_half_width * 0.5\n",
    "            # Box\n",
    "            box = plt.Rectangle(\n",
    "                (n_systems - box_half_width, lower_box),\n",
    "                box_width,\n",
    "                upper_box - lower_box,\n",
    "                fill=True,\n",
    "                facecolor=colors[i],\n",
    "                alpha=alpha_val,\n",
    "                linewidth=1,\n",
    "                edgecolor=\"black\",\n",
    "                zorder=5,\n",
    "                label=rf\"$N_{{sys}}={n_systems}$\",\n",
    "            )\n",
    "            plt.gca().add_patch(box)\n",
    "\n",
    "            # Median line\n",
    "            plt.hlines(\n",
    "                median_vals,\n",
    "                n_systems - box_half_width,\n",
    "                n_systems + box_half_width,\n",
    "                colors=\"black\",\n",
    "                linewidth=2.5,\n",
    "                zorder=10,\n",
    "            )\n",
    "\n",
    "            # Whiskers\n",
    "            plt.vlines(\n",
    "                n_systems,\n",
    "                lower_box,\n",
    "                lower_whisker,\n",
    "                colors=\"black\",\n",
    "                linestyle=\"-\",\n",
    "                linewidth=1,\n",
    "                zorder=5,\n",
    "            )\n",
    "            plt.vlines(\n",
    "                n_systems,\n",
    "                upper_box,\n",
    "                upper_whisker,\n",
    "                colors=\"black\",\n",
    "                linestyle=\"-\",\n",
    "                linewidth=1,\n",
    "                zorder=5,\n",
    "            )\n",
    "\n",
    "            # Caps on whiskers\n",
    "            plt.hlines(\n",
    "                lower_whisker,\n",
    "                n_systems - whisker_cap_width,\n",
    "                n_systems + whisker_cap_width,\n",
    "                colors=\"black\",\n",
    "                linewidth=1,\n",
    "                zorder=5,\n",
    "            )\n",
    "            plt.hlines(\n",
    "                upper_whisker,\n",
    "                n_systems - whisker_cap_width,\n",
    "                n_systems + whisker_cap_width,\n",
    "                colors=\"black\",\n",
    "                linewidth=1,\n",
    "                zorder=5,\n",
    "            )\n",
    "        elif stat_to_plot == \"mean\":\n",
    "            mean_vals = np.mean(metric_vals)\n",
    "            std_vals = np.std(metric_vals)\n",
    "            ste_vals = std_vals / np.sqrt(len(metric_vals))\n",
    "\n",
    "            plt.scatter(\n",
    "                n_systems,\n",
    "                mean_vals,\n",
    "                s=36,  # equivalent to markersize=6 squared\n",
    "                edgecolors=\"black\",\n",
    "                linewidths=0.2,\n",
    "                label=rf\"$N_{{sys}}={n_systems}$\",\n",
    "                color=colors[i],\n",
    "            )\n",
    "            plt.errorbar(\n",
    "                n_systems,\n",
    "                mean_vals,\n",
    "                yerr=ste_vals,\n",
    "                fmt=\"none\",\n",
    "                color=colors[i],\n",
    "                capsize=5,  # Add T-shaped caps to the error bars\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid stat_to_plot: {stat_to_plot}\")\n",
    "    if show_legend:\n",
    "        plt.legend(**legend_kwargs)\n",
    "    if title is not None:\n",
    "        plt.title(title, fontweight=\"bold\")\n",
    "    plt.xlabel(\"Number of Systems\", fontweight=\"bold\")\n",
    "    plt.ylabel(metric_to_plot_title, fontweight=\"bold\")\n",
    "    plt.xscale(\"log\", base=2)\n",
    "    plt.tight_layout()\n",
    "    if save_path is not None:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_to_plot = \"smape\"\n",
    "prediction_length = 512\n",
    "stat_to_plot = \"median\"\n",
    "make_scaling_plot(\n",
    "    unrolled_metrics_all_combined,\n",
    "    metric_to_plot=metric_to_plot,\n",
    "    stat_to_plot=stat_to_plot,\n",
    "    prediction_length=prediction_length,\n",
    "    colormap=\"cividis_r\",\n",
    "    show_legend=False,\n",
    "    title=rf\"$L_{{pred}}={prediction_length}$\",\n",
    "    legend_kwargs={\"loc\": \"upper right\", \"frameon\": True, \"ncol\": 1, \"fontsize\": 8},\n",
    "    save_path=f\"scalinglaw_figs/{metric_to_plot}_{prediction_length}_{stat_to_plot}.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_to_plot = \"smape\"\n",
    "prediction_length = 512\n",
    "stat_to_plot = \"mean\"\n",
    "make_scaling_plot(\n",
    "    unrolled_metrics_all_combined,\n",
    "    metric_to_plot=metric_to_plot,\n",
    "    stat_to_plot=stat_to_plot,\n",
    "    prediction_length=prediction_length,\n",
    "    colormap=\"cividis_r\",\n",
    "    show_legend=False,\n",
    "    title=rf\"$L_{{pred}}={prediction_length}$\",\n",
    "    legend_kwargs={\"loc\": \"upper right\", \"frameon\": True, \"ncol\": 1, \"fontsize\": 8},\n",
    "    save_path=f\"scalinglaw_figs/{metric_to_plot}_{prediction_length}_{stat_to_plot}.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_to_plot = \"smape\"\n",
    "prediction_length = 256\n",
    "stat_to_plot = \"mean\"\n",
    "make_scaling_plot(\n",
    "    unrolled_metrics_all_combined,\n",
    "    metric_to_plot=metric_to_plot,\n",
    "    stat_to_plot=stat_to_plot,\n",
    "    prediction_length=prediction_length,\n",
    "    colormap=\"cividis_r\",\n",
    "    show_legend=False,\n",
    "    title=rf\"$L_{{pred}}={prediction_length}$\",\n",
    "    legend_kwargs={\"loc\": \"upper right\", \"frameon\": True, \"ncol\": 1, \"fontsize\": 8},\n",
    "    save_path=f\"scalinglaw_figs/{metric_to_plot}_{prediction_length}_{stat_to_plot}.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scaling_plot_v2(\n",
    "    unrolled_metrics: dict,\n",
    "    prediction_lengths: list[int] = [128, 256, 512],\n",
    "    metric_to_plot: str = \"smape\",\n",
    "    colormap: str = \"Blues\",\n",
    "    legend_kwargs: dict = {},\n",
    "    figsize: tuple = (4, 4),\n",
    "    save_path: str | None = None,\n",
    "    use_inv_spearman: bool = True,\n",
    "    show_legend: bool = True,\n",
    "    ylim: tuple | None = None,\n",
    "    alpha_val: float = 0.8,\n",
    "    markersize: float = 5,\n",
    ") -> tuple[dict[int, dict[int, float]], dict[int, dict[int, float]], list[mlines.Line2D]]:\n",
    "    if metric_to_plot == \"smape\":\n",
    "        metric_to_plot_title = \"sMAPE\"\n",
    "    elif metric_to_plot == \"spearman\" and use_inv_spearman:\n",
    "        metric_to_plot_title = \"1 - Spearman\"\n",
    "    else:\n",
    "        metric_to_plot_title = metric_to_plot.upper()\n",
    "\n",
    "    mean_vals_dict = defaultdict(lambda: defaultdict(list))\n",
    "    std_vals_dict = defaultdict(lambda: defaultdict(list))\n",
    "    ste_vals_dict = defaultdict(lambda: defaultdict(list))\n",
    "    for ic_split, metrics_by_predlength_dict in unrolled_metrics.items():\n",
    "        n_systems = int(ic_to_n_systems[ic_split])\n",
    "        for prediction_length in prediction_lengths:\n",
    "            metric_vals = metrics_by_predlength_dict[prediction_length][metric_to_plot]\n",
    "            # get rid of nan values\n",
    "            # Handle case where metric_vals might not be a numpy array\n",
    "            if isinstance(metric_vals, (list, tuple)):\n",
    "                metric_vals = np.array(metric_vals)\n",
    "            # Filter out NaN values\n",
    "            if len(metric_vals) > 0:\n",
    "                mask = ~np.isnan(metric_vals)\n",
    "                metric_vals = metric_vals[mask]\n",
    "            if metric_to_plot == \"spearman\" and use_inv_spearman:\n",
    "                metric_vals = 1 - metric_vals\n",
    "            mean_vals_dict[prediction_length][n_systems] = np.nanmean(metric_vals)\n",
    "            std_vals_dict[prediction_length][n_systems] = np.nanstd(metric_vals)\n",
    "            ste_vals_dict[prediction_length][n_systems] = std_vals_dict[prediction_length][n_systems] / np.sqrt(\n",
    "                len(metric_vals)\n",
    "            )\n",
    "    # sort metric_at_predlength by n_systems\n",
    "    mean_vals_dict = dict(sorted(mean_vals_dict.items()))\n",
    "    std_vals_dict = dict(sorted(std_vals_dict.items()))\n",
    "    ste_vals_dict = dict(sorted(ste_vals_dict.items()))\n",
    "    # make line plot of medians of metric_at_predlength\n",
    "    colors = plt.cm.get_cmap(colormap)(np.linspace(0, 0.9, len(mean_vals_dict)))\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i, (prediction_length, metrics_dict_by_n_systems) in enumerate(mean_vals_dict.items()):\n",
    "        n_systems = list(metrics_dict_by_n_systems.keys())\n",
    "        mean_vals = np.array(list(metrics_dict_by_n_systems.values()))\n",
    "        ste_vals = np.array(list(ste_vals_dict[prediction_length].values()))\n",
    "        plt.plot(\n",
    "            n_systems,\n",
    "            mean_vals,\n",
    "            marker=\"o\",\n",
    "            markersize=markersize,\n",
    "            linestyle=\"-\",\n",
    "            label=rf\"$L_{{pred}}={prediction_length}$\",\n",
    "            color=colors[i],\n",
    "            alpha=alpha_val,\n",
    "        )\n",
    "        plt.fill_between(\n",
    "            n_systems,\n",
    "            mean_vals - ste_vals,\n",
    "            mean_vals + ste_vals,\n",
    "            alpha=0.2,\n",
    "            color=colors[i],\n",
    "        )\n",
    "\n",
    "    if show_legend:\n",
    "        legend_handles = plt.legend(**legend_kwargs)\n",
    "    else:\n",
    "        legend_handles = [\n",
    "            mlines.Line2D(\n",
    "                [0],\n",
    "                [0],\n",
    "                color=colors[i],\n",
    "                marker=\"o\",\n",
    "                markersize=markersize,\n",
    "                linestyle=\"-\",\n",
    "                alpha=alpha_val,\n",
    "                label=rf\"$L_{{pred}}={list(mean_vals_dict.keys())[i]}$\",\n",
    "            )\n",
    "            for i in range(len(mean_vals_dict))\n",
    "        ]\n",
    "\n",
    "    plt.xlabel(\"Number of Systems\", fontweight=\"bold\")\n",
    "    plt.ylabel(metric_to_plot_title, fontweight=\"bold\")\n",
    "    plt.xscale(\"log\", base=2)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(ylim)\n",
    "    plt.tight_layout()\n",
    "    if save_path is not None:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    return mean_vals_dict, ste_vals_dict, legend_handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred_lengths = list(unrolled_metrics_all_combined[\"ic2\"].keys())\n",
    "print(all_pred_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_to_plot = \"smape\"\n",
    "prediction_lengths = [128, 256, 512]\n",
    "stat_to_plot = \"mean\"\n",
    "\n",
    "mean_vals_dict, ste_vals_dict, legend_handles = make_scaling_plot_v2(\n",
    "    unrolled_metrics_all_combined,\n",
    "    metric_to_plot=metric_to_plot,\n",
    "    prediction_lengths=all_pred_lengths,\n",
    "    colormap=\"cividis\",\n",
    "    show_legend=False,\n",
    "    figsize=(4, 4),\n",
    "    alpha_val=1.0,\n",
    "    markersize=4,\n",
    "    # legend_kwargs={\"loc\": \"lower center\", \"frameon\": True, \"ncol\": 4, \"fontsize\": 5},\n",
    "    save_path=f\"scalinglaw_figs/{metric_to_plot}_combined.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 1))\n",
    "\n",
    "# Add the legend with the combined handles\n",
    "legend = plt.legend(\n",
    "    handles=legend_handles,\n",
    "    loc=\"upper center\",\n",
    "    frameon=True,\n",
    "    ncol=4,\n",
    "    framealpha=1.0,\n",
    "    fontsize=16,\n",
    ")\n",
    "\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.tight_layout(pad=0)\n",
    "plt.savefig(\"scalinglaw_figs/scalinglaw_legend_horizontal.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 3))\n",
    "\n",
    "# Add the legend with the combined handles\n",
    "legend = plt.legend(\n",
    "    handles=legend_handles,\n",
    "    loc=\"upper center\",\n",
    "    frameon=True,\n",
    "    ncol=1,\n",
    "    framealpha=1.0,\n",
    "    fontsize=16,\n",
    ")\n",
    "\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.tight_layout(pad=0)\n",
    "plt.savefig(\"scalinglaw_figs/scalinglaw_legend_vertical.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt to fit scaling law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vals_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_law(num_systems, c0, c1, alpha):\n",
    "    return c0 + c1 * num_systems ** (-alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pred_length = 128\n",
    "\n",
    "# Curve fitting\n",
    "initial_guess = [\n",
    "    1.0,\n",
    "    1.0,\n",
    "    1.0,\n",
    "]  # Initial parameter guess [c1, alpha, c2, beta]\n",
    "params, pcov = curve_fit(\n",
    "    lambda X, c0, c1, alpha: scaling_law(X, c0, c1, alpha),\n",
    "    list(mean_vals_dict[selected_pred_length].keys()),\n",
    "    list(mean_vals_dict[selected_pred_length].values()),\n",
    "    p0=initial_guess,\n",
    "    bounds=([0, 0, 0], [np.inf, np.inf, np.inf]),\n",
    "    maxfev=10000,\n",
    ")\n",
    "\n",
    "# Extract the fitted parameters\n",
    "c0, c1, alpha = params\n",
    "param_errors = np.sqrt(np.diag(pcov))\n",
    "\n",
    "mean_vals_pred = scaling_law(list(mean_vals_dict[selected_pred_length].keys()), c0, c1, alpha)\n",
    "print(f\"mean_vals_pred shape: {mean_vals_pred.shape}\")\n",
    "ss_tot = np.sum(\n",
    "    (list(mean_vals_dict[selected_pred_length].values()) - np.mean(list(mean_vals_dict[selected_pred_length].values())))\n",
    "    ** 2\n",
    ")\n",
    "ss_res = np.sum((list(mean_vals_dict[selected_pred_length].values()) - mean_vals_pred) ** 2)\n",
    "r_squared = 1 - (ss_res / ss_tot)\n",
    "print(f\"R² = {r_squared:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scaling law fit\n",
    "plt.figure(figsize=(3, 4))\n",
    "\n",
    "# Plot data and fitted curve\n",
    "plt.scatter(\n",
    "    list(mean_vals_dict[selected_pred_length].keys()),\n",
    "    list(mean_vals_dict[selected_pred_length].values()),\n",
    "    color=legend_handles[1].get_color(),\n",
    "    marker=\"o\",\n",
    "    label=r\"$L_{pred}=128$\",\n",
    ")\n",
    "plt.errorbar(\n",
    "    list(mean_vals_dict[selected_pred_length].keys()),\n",
    "    list(mean_vals_dict[selected_pred_length].values()),\n",
    "    yerr=list(ste_vals_dict[selected_pred_length].values()),\n",
    "    fmt=\"none\",\n",
    "    ecolor=legend_handles[1].get_color(),\n",
    "    capsize=2,\n",
    "    alpha=1.0,\n",
    "    elinewidth=1,\n",
    ")\n",
    "# Generate smooth curve\n",
    "x_smooth = np.logspace(\n",
    "    np.log10(min(mean_vals_dict[selected_pred_length].keys())),\n",
    "    np.log10(max(mean_vals_dict[selected_pred_length].keys())),\n",
    "    100,\n",
    ")\n",
    "y_smooth = scaling_law(x_smooth, c0, c1, alpha)\n",
    "plt.plot(\n",
    "    x_smooth,\n",
    "    y_smooth,\n",
    "    color=legend_handles[1].get_color(),\n",
    "    linestyle=\"-\",\n",
    "    label=\"Fitted Curve\",\n",
    ")\n",
    "\n",
    "# Set labels and title with scaling law formula\n",
    "plt.xlabel(\"Number of Systems\", fontweight=\"bold\")\n",
    "# plt.ylabel(\"sMAPE\", fontweight=\"bold\")\n",
    "plt.title(\n",
    "    rf\"$\\mathbb{{E}}[\\mathrm{{sMAPE}}] = {c0:.2f} + {c1:.2f} \\cdot N_{{sys}}^{{-{alpha:.4f}}}$\",\n",
    "    fontsize=10,\n",
    ")\n",
    "plt.xscale(\"log\", base=2)\n",
    "# plt.grid(True, alpha=0.3)\n",
    "plt.legend(frameon=True, fontsize=8, loc=\"upper right\")\n",
    "\n",
    "# Add R² value\n",
    "plt.text(\n",
    "    0.05,\n",
    "    0.05,\n",
    "    f\"R² = {r_squared:.4f}\",\n",
    "    transform=plt.gca().transAxes,\n",
    "    fontsize=10,\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.8),\n",
    "    ha=\"left\",\n",
    "    va=\"bottom\",\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f\"scalinglaw_figs/{metric_to_plot}_{selected_pred_length}_fit.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit scaling laws on all prediction lengths sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_law_params_by_predlength = {}\n",
    "\n",
    "for pred_length, mean_vals_dict_by_predlength in tqdm(mean_vals_dict.items(), desc=\"Fitting scaling laws\"):\n",
    "    print(f\"Fitting scaling law for prediction length {pred_length}\")\n",
    "\n",
    "    # Curve fitting\n",
    "    initial_guess = [\n",
    "        1.0,\n",
    "        1.0,\n",
    "        1.0,\n",
    "    ]  # Initial parameter guess [c1, alpha, c2, beta]\n",
    "    params, pcov = curve_fit(\n",
    "        lambda X, c0, c1, alpha: scaling_law(X, c0, c1, alpha),\n",
    "        list(mean_vals_dict_by_predlength.keys()),\n",
    "        list(mean_vals_dict_by_predlength.values()),\n",
    "        p0=initial_guess,\n",
    "        bounds=([0, 0, 0], [np.inf, np.inf, np.inf]),\n",
    "        maxfev=10000,\n",
    "    )\n",
    "\n",
    "    # Extract the fitted parameters\n",
    "    param_errors = np.sqrt(np.diag(pcov))\n",
    "\n",
    "    print(f\"Fitted parameters for prediction length {pred_length}:\")\n",
    "    print(f\"c0 = {params[0]:.4e} ± {param_errors[0]:.4e}\")\n",
    "    print(f\"c1 = {params[1]:.4e} ± {param_errors[1]:.4e}\")\n",
    "    print(f\"alpha = {params[2]:.4f} ± {param_errors[2]:.4f}\")\n",
    "\n",
    "    # compute r2 score\n",
    "    mean_vals_pred = scaling_law(list(mean_vals_dict_by_predlength.keys()), params[0], params[1], params[2])\n",
    "    ss_tot = np.sum(\n",
    "        (list(mean_vals_dict_by_predlength.values()) - np.mean(list(mean_vals_dict_by_predlength.values()))) ** 2\n",
    "    )\n",
    "    ss_res = np.sum((list(mean_vals_dict_by_predlength.values()) - mean_vals_pred) ** 2)\n",
    "    r_squared = 1 - (ss_res / ss_tot)\n",
    "    print(f\"R² = {r_squared:.4f}\")\n",
    "\n",
    "    scaling_law_params_by_predlength[pred_length] = {\n",
    "        \"params\": params,\n",
    "        \"param_errors\": param_errors,\n",
    "        \"r_squared\": r_squared,\n",
    "    }\n",
    "\n",
    "print(scaling_law_params_by_predlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scaling law fit for all prediction lengths\n",
    "plt.figure(figsize=(3, 4))\n",
    "\n",
    "# Create colormap\n",
    "colormap = \"cividis\"\n",
    "colors = plt.cm.get_cmap(colormap)(np.linspace(0, 0.9, len(scaling_law_params_by_predlength)))\n",
    "\n",
    "# Plot data and fitted curves\n",
    "for i, (pred_length, scaling_params) in enumerate(scaling_law_params_by_predlength.items()):\n",
    "    c0, c1, alpha = scaling_params[\"params\"]\n",
    "    r_squared = scaling_params[\"r_squared\"]\n",
    "\n",
    "    # Plot data points\n",
    "    plt.scatter(\n",
    "        list(mean_vals_dict[pred_length].keys()),\n",
    "        list(mean_vals_dict[pred_length].values()),\n",
    "        color=colors[i],\n",
    "        marker=\"o\",\n",
    "        label=f\"Data (pred_len={pred_length})\",\n",
    "        alpha=0.8,\n",
    "        s=20,\n",
    "    )\n",
    "\n",
    "    # plt.errorbar(\n",
    "    #     list(mean_vals_dict[pred_length].keys()),\n",
    "    #     list(mean_vals_dict[pred_length].values()),\n",
    "    #     yerr=list(ste_vals_dict[pred_length].values()),\n",
    "    #     fmt='none',\n",
    "    #     ecolor=colors[i],\n",
    "    #     capsize=2,\n",
    "    #     alpha=1.0,\n",
    "    #     elinewidth=1\n",
    "    # )\n",
    "    # Plot fitted curve\n",
    "    x_smooth = np.logspace(\n",
    "        np.log10(min(mean_vals_dict[pred_length].keys())),\n",
    "        np.log10(max(mean_vals_dict[pred_length].keys())),\n",
    "        100,\n",
    "    )\n",
    "    y_smooth = scaling_law(x_smooth, c0, c1, alpha)\n",
    "    plt.plot(\n",
    "        x_smooth,\n",
    "        y_smooth,\n",
    "        color=colors[i],\n",
    "        linestyle=\"-\",\n",
    "        linewidth=1,\n",
    "        label=f\"Fit (pred_len={pred_length}): sMAPE = {c0:.2f} + {c1:.2f} · N_sys^(-{alpha:.4f}), R² = {r_squared:.4f}\",\n",
    "    )\n",
    "\n",
    "# Set plot properties\n",
    "plt.xlabel(\"Number of Systems\", fontweight=\"bold\")\n",
    "plt.ylabel(\"sMAPE\", fontweight=\"bold\")\n",
    "plt.title(\"Scaling Law Fits\", fontweight=\"bold\")\n",
    "plt.xscale(\"log\", base=2)\n",
    "# put x ticks at 2**8, 2**9, 2**10, 2**11, 2**12, 2**13, 2**14\n",
    "plt.xticks([2**8, 2**9, 2**10, 2**11, 2**12, 2**13, 2**14])\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.legend(frameon=True, fontsize=12, loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"scalinglaw_figs/scaling_law_fits_all_pred_lengths.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit scaling law on number of systems and prediction length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scaling law function\n",
    "def scaling_law_full(num_systems, pred_length, c0, c1, alpha, c2, beta):\n",
    "    return c0 + c1 * num_systems ** (-alpha) + c2 * pred_length ** (-beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vals_dict_full = {}\n",
    "for pred_length, systems_dict in mean_vals_dict.items():\n",
    "    for num_systems, value in systems_dict.items():\n",
    "        mean_vals_dict_full[(num_systems, pred_length)] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vals_dict_full.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_length_arr = np.array(list(set([x[1] for x in mean_vals_dict_full.keys()])))\n",
    "num_systems_arr = np.array(list(set([x[0] for x in mean_vals_dict_full.keys()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_length_arr.shape)\n",
    "print(num_systems_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for curve fitting\n",
    "X = []\n",
    "y = []\n",
    "for (num_sys, pred_len), value in mean_vals_dict_full.items():\n",
    "    X.append([num_sys, pred_len])\n",
    "    y.append(value)\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curve fitting\n",
    "initial_guess = [\n",
    "    1.0,\n",
    "    1.0,\n",
    "    1.0,\n",
    "    1.0,\n",
    "    1.0,\n",
    "]  # Initial parameter guess [c0, c1, alpha, c2, beta]\n",
    "\n",
    "params, pcov = curve_fit(\n",
    "    lambda X, c0, c1, alpha, c2, beta: np.array([scaling_law_full(x[0], x[1], c0, c1, alpha, c2, beta) for x in X]),\n",
    "    X,\n",
    "    y,\n",
    "    p0=initial_guess,\n",
    "    bounds=([0, 0, 0, 0, 0], [np.inf, np.inf, np.inf, np.inf, np.inf]),\n",
    "    maxfev=10000,\n",
    ")\n",
    "\n",
    "# Extract the fitted parameters\n",
    "c0, c1, alpha, c2, beta = params\n",
    "param_errors = np.sqrt(np.diag(pcov))\n",
    "\n",
    "print(f\"Fitted parameters: c0={c0:.4f}, c1={c1:.4f}, alpha={alpha:.4f}, c2={c2:.4f}, beta={beta:.4f}\")\n",
    "print(f\"Parameter errors: {param_errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitted parameters:\")\n",
    "print(f\"c0 = {c0:.4e} ± {param_errors[0]:.4e}\")\n",
    "print(f\"c1 = {c1:.4e} ± {param_errors[0]:.4e}\")\n",
    "print(f\"alpha = {alpha:.4f} ± {param_errors[1]:.4f}\")\n",
    "print(f\"c2 = {c2:.4e} ± {param_errors[2]:.4e}\")\n",
    "print(f\"beta = {beta:.4f} ± {param_errors[3]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots for scaling law visualization\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "unique_n_systems = sorted(set(n_sys for (n_sys, _) in mean_vals_dict_full.keys()))\n",
    "unique_pred_lengths = sorted(set(pred_len for (_, pred_len) in mean_vals_dict_full.keys()))\n",
    "colors = plt.cm.cividis(np.linspace(0, 0.9, len(unique_pred_lengths)))\n",
    "\n",
    "# Plot for each prediction length\n",
    "for i, pred_len in enumerate(unique_pred_lengths):\n",
    "    # Extract data for this prediction length\n",
    "    n_systems = []\n",
    "    actual_vals = []\n",
    "    for (n_sys, p), value in mean_vals_dict_full.items():\n",
    "        if p == pred_len:\n",
    "            n_systems.append(n_sys)\n",
    "            actual_vals.append(value)\n",
    "\n",
    "    # Sort by number of systems\n",
    "    sorted_indices = np.argsort(n_systems)\n",
    "    n_systems = np.array(n_systems)[sorted_indices]\n",
    "    actual_vals = np.array(actual_vals)[sorted_indices]\n",
    "\n",
    "    # Plot actual values and fitted curve\n",
    "    plt.scatter(\n",
    "        n_systems,\n",
    "        actual_vals,\n",
    "        color=colors[i],\n",
    "        marker=\"o\",\n",
    "        label=f\"L_pred = {pred_len}\",\n",
    "    )\n",
    "\n",
    "    # Generate smooth curve\n",
    "    n_systems_smooth = np.logspace(np.log10(min(n_systems)), np.log10(max(n_systems)), 100)\n",
    "    y_smooth = [scaling_law_full(n, pred_len, c0, c1, alpha, c2, beta) for n in n_systems_smooth]\n",
    "    plt.plot(n_systems_smooth, y_smooth, color=colors[i], linestyle=\"-\", alpha=0.7)\n",
    "\n",
    "plt.xlabel(\"Number of Systems\", fontweight=\"bold\")\n",
    "plt.ylabel(\"sMAPE\", fontweight=\"bold\")\n",
    "plt.title(\"Scaling with Number of Systems\", fontweight=\"bold\")\n",
    "plt.xscale(\"log\", base=2)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(frameon=True, fontsize=8, ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"scalinglaw_figs/scaling_law_fits_all_splits.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Older box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_handles = make_box_plot(\n",
    "    unrolled_metrics=unrolled_metrics_all_combined,\n",
    "    prediction_length=selected_pred_length,\n",
    "    metric_to_plot=\"smape\",  # Specify which metric to plot\n",
    "    sort_runs=True,  # Optionally sort runs by their metric values\n",
    "    colors=bar_colors,\n",
    "    title=None,\n",
    "    title_kwargs={\"fontsize\": 10},\n",
    "    ylabel_fontsize=12,\n",
    "    show_xlabel=False,\n",
    "    box_percentile_range=(40, 60),\n",
    "    whisker_percentile_range=(25, 75),\n",
    "    alpha_val=0.8,\n",
    "    show_legend=True,\n",
    "    legend_kwargs={\"loc\": \"lower right\", \"frameon\": True, \"ncol\": 1, \"framealpha\": 1.0},\n",
    "    # save_path=\"scalinglaw_figs/smape_128.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 0.6))\n",
    "# Add the legend\n",
    "plt.legend(\n",
    "    handles=legend_handles,\n",
    "    loc=\"center\",\n",
    "    frameon=True,\n",
    "    ncol=3,\n",
    "    framealpha=1.0,\n",
    ")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.tight_layout(pad=0)\n",
    "# plt.savefig(\"ablations_figs/ablations_legend.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
