{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from dysts.metrics import compute_metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "\n",
    "from panda.chronos.pipeline import ChronosPipeline\n",
    "from panda.patchtst.pipeline import PatchTSTPipeline\n",
    "from panda.utils.data_utils import safe_standardize\n",
    "from panda.utils.plot_utils import apply_custom_style\n",
    "\n",
    "apply_custom_style(\"../config/plotting.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK = os.environ.get(\"WORK\", \"\")\n",
    "base_dir = f\"{WORK}/physics-datasets\"\n",
    "re = 450\n",
    "fpath = f\"{base_dir}/von_karman_street/vortex_street_velocities_Re_{re}_4800timepoints.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_save_dir = \"../figures/vonkarman\"\n",
    "os.makedirs(figs_save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfield = np.load(fpath, allow_pickle=True)\n",
    "vort_field = np.diff(vfield, axis=1)[..., :-1, 1] + np.diff(vfield, axis=2)[:, :-1, :, 0]\n",
    "vort_field_flattened = vort_field.reshape(vort_field.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"pft_chattn_emb_w_poly-0\"\n",
    "# run_name = \"pft_chattn_noembed_pretrained_correct-0\"  # chattn + mlm\n",
    "# run_name = \"pft_linattnpolyemb_from_scratch-0\"\n",
    "\n",
    "pft_model = PatchTSTPipeline.from_pretrained(\n",
    "    mode=\"predict\",\n",
    "    pretrain_path=f\"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/{run_name}/checkpoint-final\",\n",
    "    device_map=\"cuda:2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_ft = ChronosPipeline.from_pretrained(\n",
    "    # \"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/chronos_finetune_stand_updated-0/checkpoint-final\",\n",
    "    # \"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/chronos_mini_ft-0/checkpoint-final\",\n",
    "    \"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/chronos_t5_mini_ft-0/checkpoint-final\",\n",
    "    device_map=\"cuda:3\",\n",
    "    torch_dtype=torch.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_zs = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-mini\",\n",
    "    device_map=\"cuda:4\",\n",
    "    torch_dtype=torch.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration and Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_prediction(\n",
    "    model,\n",
    "    data: np.ndarray,\n",
    "    context_length: int,\n",
    "    prediction_length: int,\n",
    "    title: str | None = None,\n",
    "    show: bool = True,\n",
    "    transpose: bool = True,\n",
    "    indices: list[int] | None = None,\n",
    "    **kwargs,\n",
    ") -> np.ndarray:\n",
    "    context = data[:, :context_length]\n",
    "    groundtruth = data[:, context_length : context_length + prediction_length]\n",
    "    context_tensor = torch.from_numpy(context.T if transpose else context).float()\n",
    "    pred = model.predict(context_tensor, prediction_length, **kwargs).squeeze().cpu().numpy()\n",
    "    if not transpose:\n",
    "        pred = pred.T\n",
    "\n",
    "    total_length = context.shape[1] + prediction_length\n",
    "    context_ts = np.arange(context.shape[1]) / total_length\n",
    "    pred_ts = np.arange(context.shape[1], total_length) / total_length\n",
    "\n",
    "    if show:\n",
    "        if indices is None:\n",
    "            indices = [0, 1, 2]\n",
    "        fig = plt.figure(figsize=(15, 4))\n",
    "\n",
    "        outer_grid = fig.add_gridspec(1, 2, width_ratios=[0.5, 0.5], wspace=0.05)\n",
    "        gs = outer_grid[1].subgridspec(3, 1, height_ratios=[1 / 3] * 3, wspace=0, hspace=0)\n",
    "        ax_3d = fig.add_subplot(outer_grid[0], projection=\"3d\")\n",
    "        ax_3d.plot(*context[indices], alpha=0.5, color=\"black\", label=\"Context\")\n",
    "        ax_3d.plot(*groundtruth[indices], linestyle=\"--\", color=\"black\", label=\"Groundtruth\")\n",
    "        ax_3d.plot(*pred.T[indices], color=\"red\", label=\"Prediction\")\n",
    "        ax_3d.legend(loc=\"upper right\", fontsize=12)\n",
    "        ax_3d.set_xlabel(\"$x_{\" + str(indices[0]) + \"}$\")\n",
    "        ax_3d.set_ylabel(\"$x_{\" + str(indices[1]) + \"}$\")\n",
    "        ax_3d.set_zlabel(\"$x_{\" + str(indices[2]) + \"}$\")\n",
    "        if title is not None:\n",
    "            ax_3d.set_title(title)\n",
    "\n",
    "        axes_1d = [fig.add_subplot(gs[i, 0]) for i in range(3)]\n",
    "        for i, ax in zip(indices, axes_1d):\n",
    "            ax.plot(context_ts, context[i], alpha=0.5, color=\"black\")\n",
    "            ax.plot(pred_ts, groundtruth[i], linestyle=\"--\", color=\"black\")\n",
    "            ax.plot(pred_ts, pred[:, i], color=\"red\")\n",
    "            index_str = \"{\" + str(i) + \"}\"\n",
    "            ax.set_ylabel(f\"$x_{index_str}$\")\n",
    "            ax.set_aspect(\"auto\")\n",
    "        axes_1d[-1].set_xlabel(\"Time\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 512\n",
    "pca = PCA(n_components=n_components)\n",
    "pca.fit(vort_field_flattened)\n",
    "X_ts = pca.transform(vort_field_flattened)  # (T, D)\n",
    "# # safe standardize\n",
    "# X_ts = safe_standardize(X_ts, axis=0)\n",
    "eigenvectors = pca.components_  # (D, H*W)\n",
    "\n",
    "## Show low-rank structure\n",
    "plt.figure()\n",
    "plt.plot(np.arange(n_components), pca.explained_variance_ratio_)\n",
    "plt.semilogy()\n",
    "\n",
    "## Plot trajectory\n",
    "plt.figure()\n",
    "plt.plot(X_ts[:, 0], X_ts[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(pca_coeffs: np.ndarray, eigenvectors: np.ndarray, modes: int = -1) -> np.ndarray:\n",
    "    if modes == -1:\n",
    "        modes = pca_coeffs.shape[1]\n",
    "    return pca_coeffs[:, :modes] @ eigenvectors[:modes, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vort_recon = reconstruct(X_ts, eigenvectors)\n",
    "vort_recon = vort_recon.reshape(vort_field.shape[0], vort_field.shape[1], vort_field.shape[2])\n",
    "plt.figure()\n",
    "plt.imshow(vort_recon[100 + 512, :, :].T, cmap=\"seismic\")\n",
    "plt.colorbar(shrink=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 2048  # ignore transient\n",
    "stride = 1\n",
    "subsampled_pca_coeffs = X_ts[start::stride, :]\n",
    "stand_subsampled_pca_coeffs = safe_standardize(subsampled_pca_coeffs, axis=0)\n",
    "\n",
    "predictions = plot_model_prediction(\n",
    "    pft_model,\n",
    "    stand_subsampled_pca_coeffs.T,\n",
    "    context_length=512,\n",
    "    prediction_length=128,\n",
    "    limit_prediction_length=False,\n",
    "    sliding_context=True,\n",
    "    title=\"Von Karman Vortex Sheet PCA modes\",\n",
    "    indices=[0, 1, 2],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predicted_flow(\n",
    "    model,\n",
    "    data,\n",
    "    eigenvectors,\n",
    "    context_length: int,\n",
    "    prediction_length: int,\n",
    "    num_modes: int,\n",
    "    shape: tuple[int, int] = (vort_field.shape[1], vort_field.shape[2]),\n",
    "    transpose: bool = False,\n",
    "    standardize: bool = False,\n",
    "    batch_size: int | None = None,\n",
    "    time_indices: list[int] | None = None,\n",
    "    save_path: str | None = None,\n",
    "    camera_ready: bool = False,\n",
    "    cmap_name=\"seismic\",\n",
    "    base_figsize=(5, 5),\n",
    "    suptitle: str | None = None,\n",
    "    suptitle_y: float = 1.0,\n",
    "    **kwargs,\n",
    "):\n",
    "    context = data[:context_length, :num_modes]\n",
    "    groundtruth = data[context_length : context_length + prediction_length, :num_modes]\n",
    "\n",
    "    if standardize:\n",
    "        context = safe_standardize(context, axis=0)\n",
    "        groundtruth = safe_standardize(groundtruth, axis=0)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    context_tensor = torch.from_numpy(context).float()\n",
    "\n",
    "    if transpose:\n",
    "        context_tensor = context_tensor.T\n",
    "\n",
    "    if batch_size is None:\n",
    "        pred = model.predict(context_tensor, prediction_length, **kwargs)\n",
    "    else:\n",
    "        pred = []\n",
    "        for i in range(0, context_tensor.shape[0], batch_size):\n",
    "            pred.append(model.predict(context_tensor[i : i + batch_size], prediction_length, **kwargs))\n",
    "        pred = torch.cat(pred, dim=0)\n",
    "\n",
    "    pred = pred.squeeze().detach().cpu().numpy()\n",
    "    if transpose:\n",
    "        pred = pred.T\n",
    "\n",
    "    recon = reconstruct(pred, eigenvectors, modes=num_modes)\n",
    "    recon = recon.reshape(prediction_length, shape[0], shape[1])\n",
    "    groundtruth = reconstruct(groundtruth, eigenvectors, modes=num_modes)\n",
    "    groundtruth = groundtruth.reshape(prediction_length, shape[0], shape[1])\n",
    "    vabs = max(np.abs(groundtruth.min()), np.abs(groundtruth.max()))\n",
    "\n",
    "    if time_indices is None:\n",
    "        time_indices = list(range(0, prediction_length, stride))\n",
    "\n",
    "    aspect_ratio = shape[0] / shape[1]\n",
    "    fig = plt.figure(\n",
    "        figsize=(\n",
    "            base_figsize[0] * (len(time_indices)) / aspect_ratio,\n",
    "            base_figsize[1] * aspect_ratio,\n",
    "        )\n",
    "    )\n",
    "    gs = fig.add_gridspec(\n",
    "        2,\n",
    "        len(time_indices),\n",
    "        width_ratios=[1] * (len(time_indices)),\n",
    "        height_ratios=[1, 1],\n",
    "        wspace=0,\n",
    "        hspace=0,\n",
    "    )\n",
    "    axes = np.array([[fig.add_subplot(gs[i, j]) for j in range(len(time_indices))] for i in range(2)])\n",
    "    # for i, index in enumerate([0] + time_indices):\n",
    "    print(time_indices)\n",
    "    for i, index in enumerate(time_indices):\n",
    "        groundtruth_slice = groundtruth[index, :, :]\n",
    "        recon_slice = recon[index, :, :]\n",
    "\n",
    "        gax = axes[0, i].imshow(\n",
    "            groundtruth_slice,\n",
    "            vmin=-vabs,\n",
    "            vmax=vabs,\n",
    "            cmap=cmap_name,\n",
    "        )\n",
    "\n",
    "        axes[0, i].spines[\"top\"].set_visible(True)\n",
    "        axes[0, i].spines[\"right\"].set_visible(True)\n",
    "        axes[0, i].spines[\"bottom\"].set_visible(True)\n",
    "        axes[0, i].spines[\"left\"].set_visible(True)\n",
    "        axes[0, i].spines[\"top\"].set_color(\"black\")\n",
    "        axes[0, i].spines[\"right\"].set_color(\"black\")\n",
    "        axes[0, i].spines[\"bottom\"].set_color(\"black\")\n",
    "        axes[0, i].spines[\"left\"].set_color(\"black\")\n",
    "\n",
    "        axes[0, i].set_title(\n",
    "            # f\"t={context_length}\" + (f\" + {index}\" if index > 0 else \"\"),\n",
    "            \"t = context\" + (f\" + {index + 1}\" if index > 0 else \"\"),\n",
    "            fontsize=12,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "        axes[0, i].set_xticks([])\n",
    "        axes[0, i].set_yticks([])\n",
    "\n",
    "        rax = axes[1, i].imshow(\n",
    "            recon_slice,\n",
    "            vmin=-vabs,\n",
    "            vmax=vabs,\n",
    "            cmap=cmap_name,\n",
    "        )\n",
    "        axes[1, i].spines[\"top\"].set_visible(True)\n",
    "        axes[1, i].spines[\"right\"].set_visible(True)\n",
    "        axes[1, i].spines[\"bottom\"].set_visible(True)\n",
    "        axes[1, i].spines[\"left\"].set_visible(True)\n",
    "        axes[1, i].spines[\"top\"].set_color(\"black\")\n",
    "        axes[1, i].spines[\"right\"].set_color(\"black\")\n",
    "        axes[1, i].spines[\"bottom\"].set_color(\"black\")\n",
    "        axes[1, i].spines[\"left\"].set_color(\"black\")\n",
    "\n",
    "        axes[1, i].set_xticks([])\n",
    "        axes[1, i].set_yticks([])\n",
    "\n",
    "        circle = plt.Circle((0.5 * shape[1] + 1, 0.145 * shape[0]), 5, fill=True, color=\"black\")\n",
    "        axes[0, i].add_patch(circle)\n",
    "        circle = plt.Circle((0.5 * shape[1] + 1, 0.145 * shape[0]), 5, fill=True, color=\"black\")\n",
    "        axes[1, i].add_patch(circle)\n",
    "\n",
    "    axes[0, 0].set_ylabel(\"Ground Truth\", fontweight=\"bold\", fontsize=16)\n",
    "    axes[1, 0].set_ylabel(\"Predictions\", fontweight=\"bold\", fontsize=16)\n",
    "\n",
    "    if suptitle is not None:\n",
    "        plt.suptitle(suptitle, fontweight=\"bold\", fontsize=18, ha=\"center\", y=suptitle_y)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rollout_metrics(\n",
    "    model,\n",
    "    data,\n",
    "    eigenvectors,\n",
    "    num_modes: int,\n",
    "    context_length: int,\n",
    "    prediction_length: int,\n",
    "    time_interval: int = 64,\n",
    "    shape: tuple[int, int] = (vort_field.shape[1], vort_field.shape[2]),\n",
    "    transpose: bool = False,\n",
    "    batch_size: int | None = None,\n",
    "    compute_metrics_on_recons: bool = True,\n",
    "    verbose: bool = False,\n",
    "    **kwargs,\n",
    "):\n",
    "    context = data[:context_length, :num_modes]\n",
    "    groundtruth = data[context_length : context_length + prediction_length, :num_modes]\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    context_tensor = torch.from_numpy(context).float()\n",
    "    if transpose:\n",
    "        context_tensor = context_tensor.T\n",
    "\n",
    "    if batch_size is None:\n",
    "        pred = model.predict(context_tensor, prediction_length, **kwargs)\n",
    "    else:\n",
    "        pred = []\n",
    "        for i in range(0, context_tensor.shape[0], batch_size):\n",
    "            pred.append(model.predict(context_tensor[i : i + batch_size], prediction_length, **kwargs))\n",
    "        pred = torch.cat(pred, dim=0)\n",
    "\n",
    "    pred = pred.squeeze().detach().cpu().numpy()\n",
    "    if transpose:\n",
    "        pred = pred.T\n",
    "\n",
    "    rollout_time_intervals = np.arange(time_interval, prediction_length + time_interval, time_interval)\n",
    "\n",
    "    metrics = {}\n",
    "    if compute_metrics_on_recons:\n",
    "        recon = reconstruct(pred, eigenvectors, modes=num_modes)\n",
    "        recon = recon.reshape(prediction_length, shape[0], shape[1])\n",
    "        groundtruth = reconstruct(groundtruth, eigenvectors, modes=num_modes)\n",
    "        groundtruth = groundtruth.reshape(prediction_length, shape[0], shape[1])\n",
    "\n",
    "        for t in rollout_time_intervals:\n",
    "            metrics[t] = compute_metrics(recon[0:t], groundtruth[0:t], include=[\"mae\", \"mse\", \"smape\"])\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(f\"pred shape: {pred.shape}\")\n",
    "            print(f\"groundtruth shape: {groundtruth.shape}\")\n",
    "\n",
    "        for t in rollout_time_intervals:\n",
    "            metrics[t] = compute_metrics(pred[0:t], groundtruth[0:t], include=[\"mae\", \"mse\", \"smape\"])\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 1\n",
    "start = 2048  # ignore transient\n",
    "num_modes = 64\n",
    "context_length = 512\n",
    "prediction_length = 128\n",
    "time_indices = [15, 31, 63, 127]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicted_flow(\n",
    "    pft_model,\n",
    "    X_ts[start::stride],\n",
    "    eigenvectors,\n",
    "    context_length=context_length,\n",
    "    prediction_length=prediction_length,\n",
    "    num_modes=num_modes,\n",
    "    sliding_context=True,\n",
    "    limit_prediction_length=False,\n",
    "    time_indices=time_indices,\n",
    "    cmap_name=\"RdBu\",\n",
    "    camera_ready=False,\n",
    "    base_figsize=(4, 4),\n",
    "    save_path=os.path.join(figs_save_dir, \"von_karman_our_model.pdf\"),\n",
    "    suptitle=\"von Kármán Vortex Street\",\n",
    "    suptitle_y=0.98,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicted_flow(\n",
    "    chronos_ft,\n",
    "    X_ts[start::stride],\n",
    "    eigenvectors,\n",
    "    context_length=context_length,\n",
    "    prediction_length=prediction_length,\n",
    "    num_modes=num_modes,\n",
    "    batch_size=100,\n",
    "    transpose=True,\n",
    "    limit_prediction_length=False,\n",
    "    num_samples=1,\n",
    "    time_indices=time_indices,\n",
    "    cmap_name=\"RdBu\",\n",
    "    camera_ready=False,\n",
    "    save_path=os.path.join(figs_save_dir, \"von_karman_chronos_ft.pdf\"),\n",
    "    suptitle=\"Chronos Finetune\",\n",
    "    deterministic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicted_flow(\n",
    "    chronos_zs,\n",
    "    X_ts[start::stride],\n",
    "    eigenvectors,\n",
    "    context_length=context_length,\n",
    "    prediction_length=prediction_length,\n",
    "    num_modes=num_modes,\n",
    "    batch_size=100,\n",
    "    transpose=True,\n",
    "    limit_prediction_length=False,\n",
    "    num_samples=1,\n",
    "    time_indices=time_indices,\n",
    "    cmap_name=\"RdBu\",\n",
    "    camera_ready=False,\n",
    "    save_path=os.path.join(figs_save_dir, \"von_karman_chronos_zs.pdf\"),\n",
    "    suptitle=\"Chronos ZS\",\n",
    "    deterministic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_on_recons = True\n",
    "use_chronos_deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = compute_rollout_metrics(\n",
    "    pft_model,\n",
    "    X_ts[start::stride],\n",
    "    eigenvectors,\n",
    "    num_modes=num_modes,\n",
    "    context_length=context_length,\n",
    "    prediction_length=512,\n",
    "    time_interval=64,\n",
    "    sliding_context=True,\n",
    "    limit_prediction_length=False,\n",
    "    compute_metrics_on_recons=compute_metrics_on_recons,\n",
    ")\n",
    "smape_metrics = {t: metrics[t][\"smape\"] for t in metrics.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_chronos_ft = compute_rollout_metrics(\n",
    "    chronos_ft,\n",
    "    X_ts[start::stride],\n",
    "    eigenvectors,\n",
    "    num_modes=num_modes,\n",
    "    context_length=context_length,\n",
    "    prediction_length=512,\n",
    "    time_interval=64,\n",
    "    batch_size=100,\n",
    "    transpose=True,\n",
    "    limit_prediction_length=False,\n",
    "    num_samples=1,\n",
    "    compute_metrics_on_recons=compute_metrics_on_recons,\n",
    "    deterministic=use_chronos_deterministic,\n",
    ")\n",
    "smape_metrics_chronos_ft = {t: metrics_chronos_ft[t][\"smape\"] for t in metrics_chronos_ft.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_chronos_zs = compute_rollout_metrics(\n",
    "    chronos_zs,\n",
    "    X_ts[start::stride],\n",
    "    eigenvectors,\n",
    "    num_modes=num_modes,\n",
    "    context_length=context_length,\n",
    "    prediction_length=512,\n",
    "    time_interval=64,\n",
    "    batch_size=100,\n",
    "    transpose=True,\n",
    "    limit_prediction_length=False,\n",
    "    num_samples=1,\n",
    "    compute_metrics_on_recons=compute_metrics_on_recons,\n",
    "    deterministic=use_chronos_deterministic,\n",
    ")\n",
    "smape_metrics_chronos_zs = {t: metrics_chronos_zs[t][\"smape\"] for t in metrics_chronos_zs.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics across multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random uniform sample start_times in interval [512, 3072]\n",
    "n_runs = 10\n",
    "# rseed = 1234\n",
    "# rng = np.random.default_rng(rseed)\n",
    "# start_times = np.random.choice(start_times, size=n_runs, replace=False)\n",
    "start_times = np.arange(512, 3072, 256)\n",
    "start_times = start_times.astype(int)\n",
    "print(f\"{len(start_times)} start_times: {start_times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict with keys as times t and values as list of smape values for each run\n",
    "our_model_rollout_metrics = defaultdict(dict)\n",
    "for start_time in tqdm(start_times, desc=\"Running rollouts\"):\n",
    "    metrics = compute_rollout_metrics(\n",
    "        pft_model,\n",
    "        X_ts[start_time::stride],\n",
    "        eigenvectors,\n",
    "        num_modes=num_modes,\n",
    "        context_length=context_length,\n",
    "        prediction_length=512,\n",
    "        time_interval=64,\n",
    "        sliding_context=True,\n",
    "        limit_prediction_length=False,\n",
    "        verbose=False,\n",
    "    )\n",
    "    for t, metric in metrics.items():\n",
    "        for metric_name, metric_val in metric.items():\n",
    "            if t not in our_model_rollout_metrics[metric_name]:\n",
    "                our_model_rollout_metrics[metric_name][t] = []\n",
    "            our_model_rollout_metrics[metric_name][t].append(metric_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict with keys as times t and values as list of smape values for each run\n",
    "chronos_ft_rollout_metrics = defaultdict(dict)\n",
    "for start_time in tqdm(start_times, desc=\"Running rollouts\"):\n",
    "    metrics_chronos_ft = compute_rollout_metrics(\n",
    "        chronos_ft,\n",
    "        X_ts[start_time::stride],\n",
    "        eigenvectors,\n",
    "        num_modes=num_modes,\n",
    "        context_length=context_length,\n",
    "        prediction_length=512,\n",
    "        time_interval=64,\n",
    "        batch_size=100,\n",
    "        transpose=True,\n",
    "        limit_prediction_length=False,\n",
    "        num_samples=1,\n",
    "        deterministic=use_chronos_deterministic,\n",
    "    )\n",
    "    for t, metric in metrics_chronos_ft.items():\n",
    "        for metric_name, metric_val in metric.items():\n",
    "            if t not in chronos_ft_rollout_metrics[metric_name]:\n",
    "                chronos_ft_rollout_metrics[metric_name][t] = []\n",
    "            chronos_ft_rollout_metrics[metric_name][t].append(metric_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict with keys as times t and values as list of smape values for each run\n",
    "chronos_zs_rollout_metrics = defaultdict(dict)\n",
    "for start_time in tqdm(start_times, desc=\"Running rollouts\"):\n",
    "    metrics_chronos_ft = compute_rollout_metrics(\n",
    "        chronos_zs,\n",
    "        X_ts[start_time::stride],\n",
    "        eigenvectors,\n",
    "        num_modes=num_modes,\n",
    "        context_length=context_length,\n",
    "        prediction_length=512,\n",
    "        time_interval=64,\n",
    "        batch_size=100,\n",
    "        transpose=True,\n",
    "        limit_prediction_length=False,\n",
    "        num_samples=1,\n",
    "        deterministic=use_chronos_deterministic,\n",
    "    )\n",
    "    for t, metric_dict in metrics_chronos_ft.items():\n",
    "        for metric_name, metric_val in metric_dict.items():\n",
    "            if t not in chronos_zs_rollout_metrics[metric_name]:\n",
    "                chronos_zs_rollout_metrics[metric_name][t] = []\n",
    "            chronos_zs_rollout_metrics[metric_name][t].append(metric_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean, standard deviation, and standard error for each model\n",
    "def calculate_stats(data_dict):\n",
    "    mean_vals = {t: np.mean(v) for t, v in data_dict.items()}\n",
    "    median_vals = {t: np.median(v) for t, v in data_dict.items()}\n",
    "    std_vals = {t: np.std(v) for t, v in data_dict.items()}\n",
    "    ste_vals = {t: std_vals[t] / np.sqrt(len(data_dict[t])) for t in data_dict.keys()}\n",
    "    return mean_vals, median_vals, std_vals, ste_vals\n",
    "\n",
    "\n",
    "# Helper function to plot a model's results with error bands\n",
    "def plot_model_results(mean_dict, ste_dict, marker, label):\n",
    "    x_values = list(mean_dict.keys())\n",
    "    y_values = list(mean_dict.values())\n",
    "    y_errors = list(ste_dict.values())\n",
    "\n",
    "    plt.plot(x_values, y_values, marker=marker, label=label)\n",
    "    plt.fill_between(\n",
    "        x_values,\n",
    "        np.array(y_values) - np.array(y_errors),\n",
    "        np.array(y_values) + np.array(y_errors),\n",
    "        alpha=0.1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name = \"mae\"\n",
    "metric_name_title = \"MAE\"\n",
    "# Calculate statistics for all models\n",
    "mean_metric_ours, median_metric_ours, _, ste_metric_ours = calculate_stats(our_model_rollout_metrics[metric_name])\n",
    "mean_metric_chronos_ft, median_metric_chronos_ft, _, ste_metric_chronos_ft = calculate_stats(\n",
    "    chronos_ft_rollout_metrics[metric_name]\n",
    ")\n",
    "mean_metric_chronos_zs, median_metric_chronos_zs, _, ste_metric_chronos_zs = calculate_stats(\n",
    "    chronos_zs_rollout_metrics[metric_name]\n",
    ")\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(4, 3))\n",
    "\n",
    "# Plot each model\n",
    "plot_model_results(mean_metric_ours, ste_metric_ours, \"o\", label=\"Panda\")\n",
    "plot_model_results(mean_metric_chronos_ft, ste_metric_chronos_ft, \"s\", label=\"Chronos 20M SFT\")\n",
    "plot_model_results(mean_metric_chronos_zs, ste_metric_chronos_zs, \"v\", label=\"Chronos 20M\")\n",
    "\n",
    "# Add labels and show\n",
    "plt.xlabel(\"Prediction Length\", fontweight=\"bold\")\n",
    "plt.xticks(list(mean_metric_ours.keys()))\n",
    "plt.title(\"von Kármán Vortex Street\", fontweight=\"bold\")\n",
    "plt.ylabel(metric_name_title, fontweight=\"bold\")\n",
    "# Set y-axis to use scientific notation\n",
    "plt.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "plt.legend(loc=\"lower right\", frameon=True, fontsize=7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    os.path.join(figs_save_dir, f\"vonkarman_all_models_{metric_name}.pdf\"),\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_combined = {\n",
    "    \"Panda\": our_model_rollout_metrics,\n",
    "    \"Chronos 20M SFT\": chronos_ft_rollout_metrics,\n",
    "    \"Chronos 20M\": chronos_zs_rollout_metrics,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "save_dir = \"../outputs/vonkarman\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "with open(os.path.join(save_dir, \"vonkarman_metrics_combined.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(metrics_combined, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panda_jeff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
