{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from panda.patchtst.pipeline import PatchTSTPipeline\n",
    "from panda.utils.plot_utils import (\n",
    "    apply_custom_style,\n",
    "    plot_trajs_multivariate,\n",
    ")\n",
    "\n",
    "apply_custom_style(\"../config/plotting.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = PatchTSTPipeline.from_pretrained(\n",
    "    mode=\"pretrain\",\n",
    "    pretrain_path=\"GilpinLab/panda_mlm\",\n",
    "    device_map=\"cuda:0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_completion(\n",
    "    pipeline,\n",
    "    context: np.ndarray,\n",
    "    return_normalized_completions: bool = False,\n",
    "    verbose: bool = True,\n",
    "    **kwargs,\n",
    "):\n",
    "    # Prepare input tensor\n",
    "    context_tensor = torch.from_numpy(context.T).float().to(pipeline.device)[None, ...]\n",
    "    # Generate completions\n",
    "    completions_output = pipeline.model.generate_completions(\n",
    "        context_tensor,\n",
    "        past_observed_mask=None,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"context_tensor shape: {context_tensor.shape}\")\n",
    "        print(f\"completions output shape: {completions_output.completions.shape}\")\n",
    "\n",
    "    # Extract shapes and data\n",
    "    patch_size = completions_output.completions.shape[-1]\n",
    "\n",
    "    # Check for required outputs\n",
    "    if any(x is None for x in [completions_output.mask, completions_output.patched_past_values]):\n",
    "        raise ValueError(\"Required completion outputs are None\")\n",
    "\n",
    "    # Process tensors to numpy arrays\n",
    "    def process_tensor(tensor, reshape=True):\n",
    "        if reshape:\n",
    "            return (\n",
    "                tensor.reshape(context_tensor.shape[0], context_tensor.shape[-1], -1)\n",
    "                .detach()\n",
    "                .cpu()\n",
    "                .numpy()\n",
    "                .transpose(0, 2, 1)\n",
    "            )\n",
    "        return tensor.detach().cpu().numpy()\n",
    "\n",
    "    completions = process_tensor(completions_output.completions)\n",
    "    processed_context = process_tensor(completions_output.patched_past_values)\n",
    "    patch_mask = process_tensor(completions_output.mask, reshape=False)\n",
    "    timestep_mask = np.repeat(patch_mask, repeats=patch_size, axis=2)\n",
    "\n",
    "    # Denormalize if needed\n",
    "    if not return_normalized_completions:\n",
    "        if completions_output.loc is None or completions_output.scale is None:\n",
    "            raise ValueError(\"Loc or scale is None\")\n",
    "        loc = completions_output.loc.detach().cpu().numpy()\n",
    "        scale = completions_output.scale.detach().cpu().numpy()\n",
    "        completions = completions * scale + loc\n",
    "        processed_context = processed_context * scale + loc\n",
    "\n",
    "    # Reshape for plotting\n",
    "    processed_context = processed_context.squeeze(0).transpose(1, 0)\n",
    "    completions = completions.squeeze(0).transpose(1, 0)\n",
    "    timestep_mask = timestep_mask.squeeze(0)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"processed context shape: {processed_context.shape}\")\n",
    "        print(f\"completions shape: {completions.shape}\")\n",
    "        print(f\"timestep mask shape: {timestep_mask.shape}\")\n",
    "\n",
    "    return completions, processed_context, timestep_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_completion(\n",
    "    completions,\n",
    "    processed_context,\n",
    "    timestep_mask,\n",
    "    figsize: tuple[int, int] = (6, 8),\n",
    "    save_path: str | None = None,\n",
    "):\n",
    "    n_timesteps = processed_context.shape[1]\n",
    "    assert n_timesteps == completions.shape[1] == processed_context.shape[1]\n",
    "\n",
    "    # Create figure with grid layout\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    gs = gridspec.GridSpec(4, 1, height_ratios=[3, 1, 1, 1])\n",
    "\n",
    "    # Create axes\n",
    "    ax_3d = fig.add_subplot(gs[0], projection=\"3d\")\n",
    "    axes_2d = [fig.add_subplot(gs[i]) for i in range(1, 4)]\n",
    "\n",
    "    # Plot completions in 3D\n",
    "    ax_3d.plot(\n",
    "        processed_context[0, :],\n",
    "        processed_context[1, :],\n",
    "        processed_context[2, :],\n",
    "        alpha=0.5,\n",
    "        color=\"black\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    # ax_3d.set_title(\"Completions\", y=0.94, fontweight=\"bold\")\n",
    "    ax_3d.axis(\"off\")\n",
    "    ax_3d.grid(False)\n",
    "\n",
    "    # Plot masked segments in 3D\n",
    "    mask_bool = timestep_mask.astype(bool)\n",
    "    for dim in range(3):\n",
    "        # Find contiguous blocks in mask\n",
    "        change_indices = np.where(np.diff(np.concatenate(([False], mask_bool[dim], [False]))))[0]\n",
    "\n",
    "        # Plot each contiguous block\n",
    "        for i in range(0, len(change_indices), 2):\n",
    "            if i + 1 < len(change_indices):\n",
    "                start_idx, end_idx = change_indices[i], change_indices[i + 1]\n",
    "                # Plot masked parts in red\n",
    "                ax_3d.plot(\n",
    "                    completions[0, start_idx:end_idx],\n",
    "                    completions[1, start_idx:end_idx],\n",
    "                    completions[2, start_idx:end_idx],\n",
    "                    alpha=1,\n",
    "                    color=\"red\",\n",
    "                    linewidth=2,\n",
    "                    zorder=10,\n",
    "                )\n",
    "                # Plot masked parts in red\n",
    "                ax_3d.plot(\n",
    "                    processed_context[0, start_idx:end_idx],\n",
    "                    processed_context[1, start_idx:end_idx],\n",
    "                    processed_context[2, start_idx:end_idx],\n",
    "                    alpha=1,\n",
    "                    color=\"black\",\n",
    "                    linewidth=2,\n",
    "                )\n",
    "\n",
    "    # Plot univariate series for each dimension\n",
    "    for dim, ax in enumerate(axes_2d):\n",
    "        mask_bool_dim = timestep_mask[dim, :].astype(bool)\n",
    "\n",
    "        # Plot context\n",
    "        ax.plot(processed_context[dim, :], alpha=0.5, color=\"black\", linewidth=2)\n",
    "\n",
    "        # Find segments where mask changes\n",
    "        diffs = np.diff(mask_bool_dim.astype(int))\n",
    "        change_indices = np.where(diffs)[0]\n",
    "        if not mask_bool_dim[0]:\n",
    "            change_indices = np.concatenate(([0], change_indices))\n",
    "        segment_indices = np.concatenate((change_indices, [n_timesteps]))\n",
    "\n",
    "        # Plot completions for masked segments\n",
    "        segments = zip(segment_indices[:-1], segment_indices[1:])\n",
    "        masked_segments = [idx for i, idx in enumerate(segments) if (i + 1) % 2 == 1]\n",
    "        for start, end in masked_segments:\n",
    "            if end < n_timesteps - 1:\n",
    "                end += 1\n",
    "            ax.plot(\n",
    "                range(start, end),\n",
    "                completions[dim, start:end],\n",
    "                alpha=1,\n",
    "                color=\"red\",\n",
    "                linewidth=2,\n",
    "                zorder=10,\n",
    "            )\n",
    "            ax.plot(\n",
    "                range(start, end),\n",
    "                processed_context[dim, start:end],\n",
    "                alpha=1,\n",
    "                color=\"black\",\n",
    "                linewidth=2,\n",
    "            )\n",
    "\n",
    "        # Fill between completions and context\n",
    "        ax.fill_between(\n",
    "            range(n_timesteps),\n",
    "            processed_context[dim, :],\n",
    "            completions[dim, :],\n",
    "            where=~mask_bool_dim,\n",
    "            alpha=0.2,\n",
    "        )\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Held-Out Skew System from Saved Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from panda.utils import init_skew_system_from_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dir = \"../data/params_test_zeroshot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_json_path_test = os.path.join(params_dir, \"filtered_params_dict.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_params_dict_test = json.load(open(parameters_json_path_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Found {len(saved_params_dict_test.keys())} systems with successful param perts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Skew System Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_sys_name = \"SprottMore_CircadianRhythm\"\n",
    "# skew_sys_name = \"PehlivanWei_Duffing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parameters\n",
    "skew_sys_params = saved_params_dict_test[skew_sys_name][0]\n",
    "\n",
    "is_skew = \"_\" in skew_sys_name\n",
    "if is_skew:\n",
    "    driver_name, response_name = skew_sys_name.split(\"_\")\n",
    "    sys = init_skew_system_from_params(driver_name, response_name, skew_sys_params)\n",
    "else:\n",
    "    raise ValueError(f\"System {skew_sys_name} is not a skew system\")\n",
    "\n",
    "# Set initial condition\n",
    "sys.ic = np.array(skew_sys_params[\"ic\"])\n",
    "print(sys.ic)\n",
    "\n",
    "if not sys.has_jacobian():\n",
    "    print(f\"Jacobian not implemented for {skew_sys_name}\")\n",
    "\n",
    "\n",
    "# Make trajectory\n",
    "num_timesteps = 4096\n",
    "num_periods = 40\n",
    "\n",
    "ts, traj = sys.make_trajectory(\n",
    "    num_timesteps,\n",
    "    pts_per_period=num_timesteps // num_periods,\n",
    "    return_times=True,\n",
    "    atol=1e-10,\n",
    "    rtol=1e-8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transient_frac = 0.05\n",
    "transient_length = int(transient_frac * num_timesteps)\n",
    "\n",
    "trajectory_to_plot = traj[None, transient_length:, :].transpose(0, 2, 1)\n",
    "driver_coords = trajectory_to_plot[:, : sys.driver_dim]\n",
    "response_coords = trajectory_to_plot[:, sys.driver_dim :]\n",
    "for name, coords in [\n",
    "    (\"driver\", driver_coords),\n",
    "    (\"response\", response_coords),\n",
    "]:\n",
    "    plot_trajs_multivariate(\n",
    "        coords,\n",
    "        save_dir=None,\n",
    "        plot_name=f\"reconstructed_{skew_sys_name}_{name}\",\n",
    "        standardize=True,\n",
    "        plot_projections=False,\n",
    "        show_plot=True,\n",
    "    )\n",
    "\n",
    "skew_response_traj = traj[:, sys.driver_dim :]\n",
    "print(f\"Skew response trajectory shape: {skew_response_traj.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 1024  # actually min(4096, context_length + start_time)\n",
    "\n",
    "show_plot = True\n",
    "save_plot = False\n",
    "\n",
    "sample_idx, start_time, subsample_interval = 0, 1024, 1\n",
    "\n",
    "skew_response_trajectory = skew_response_traj.T[:, ::subsample_interval]\n",
    "\n",
    "end_time = start_time + context_length\n",
    "\n",
    "completions, processed_context, timestep_mask = get_model_completion(\n",
    "    model_pipeline,\n",
    "    skew_response_trajectory[:, start_time:end_time],  # context\n",
    "    return_normalized_completions=False,\n",
    "    verbose=False,\n",
    ")\n",
    "if show_plot:\n",
    "    plot_model_completion(\n",
    "        completions,\n",
    "        processed_context,\n",
    "        timestep_mask,\n",
    "        figsize=(6, 8),\n",
    "        save_path=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completions.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dystformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
