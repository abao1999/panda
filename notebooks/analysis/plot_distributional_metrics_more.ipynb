{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from panda.utils import (\n",
    "    apply_custom_style,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_custom_style(\"../config/plotting.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_COLORS = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = os.getenv(\"WORK\", \"\")\n",
    "DATA_DIR = os.path.join(WORK_DIR, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_metric_fnames(save_dir):\n",
    "    fnames = [\n",
    "        f\n",
    "        for f in os.listdir(save_dir)\n",
    "        if f.endswith(\".json\") and \"distributional_metrics\" in f\n",
    "    ]\n",
    "\n",
    "    def extract_window(fname):\n",
    "        m = re.search(r\"window-(\\d+)\", fname)\n",
    "        return int(m.group(1)) if m else float(\"inf\")\n",
    "\n",
    "    return sorted(fnames, key=extract_window)\n",
    "\n",
    "\n",
    "panda_metrics_save_dir = (\n",
    "    f\"{WORK_DIR}/eval_results/panda/pft_chattn_emb_w_poly-0/test_zeroshot/metrics_run2\"\n",
    ")\n",
    "# NOTE: we don't have for chronos_nondeterministic yet (very soon), just replace \"chronos\" with \"chronos_nondeterministic\" in the paths below\n",
    "chronos_sft_metrics_save_dir = (\n",
    "    f\"{WORK_DIR}/eval_results/chronos/chronos_t5_mini_ft-0/test_zeroshot/metrics_run2\"\n",
    ")\n",
    "chronos_zs_metrics_save_dir = (\n",
    "    f\"{WORK_DIR}/eval_results/chronos/chronos_mini_zeroshot/test_zeroshot/metrics_run2\"\n",
    ")\n",
    "\n",
    "panda_metrics_fnames = get_sorted_metric_fnames(panda_metrics_save_dir)\n",
    "chronos_sft_metrics_fnames = get_sorted_metric_fnames(chronos_sft_metrics_save_dir)\n",
    "chronos_zs_metrics_fnames = get_sorted_metric_fnames(chronos_zs_metrics_save_dir)\n",
    "\n",
    "print(f\"Found {len(panda_metrics_fnames)} panda metrics files: {panda_metrics_fnames}\")\n",
    "print(\n",
    "    f\"Found {len(chronos_sft_metrics_fnames)} chronos sft metrics files: {chronos_sft_metrics_fnames}\"\n",
    ")\n",
    "print(\n",
    "    f\"Found {len(chronos_zs_metrics_fnames)} chronos zs metrics files: {chronos_zs_metrics_fnames}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_fpath = os.path.join(chronos_sft_metrics_save_dir, chronos_zs_metrics_fnames[0])\n",
    "with open(metrics_fpath, \"rb\") as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "print(metrics.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[\"128\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For accumulating values across all files, for both panda and chronos_sft metrics\n",
    "\n",
    "\n",
    "def filter_none(values):\n",
    "    \"\"\"Remove None values from a list.\"\"\"\n",
    "    return [v for v in values if v is not None]\n",
    "\n",
    "\n",
    "def accumulate_metrics(metrics_fnames, metrics_save_dir):\n",
    "    avg_hellinger_accum = {\n",
    "        \"pred_with_context\": defaultdict(lambda: defaultdict(list)),\n",
    "    }\n",
    "    kld_accum = {\n",
    "        \"pred_with_context\": defaultdict(lambda: defaultdict(list)),\n",
    "    }\n",
    "    corr_gpdim_accum = {\n",
    "        \"pred_with_context\": defaultdict(lambda: defaultdict(list)),\n",
    "    }\n",
    "    gpdim_gt_with_context_accum = {\n",
    "        \"pred_with_context\": defaultdict(lambda: defaultdict(list)),\n",
    "    }\n",
    "    gpdim_pred_with_context_accum = {\n",
    "        \"pred_with_context\": defaultdict(lambda: defaultdict(list)),\n",
    "    }\n",
    "    prediction_time_accum = defaultdict(list)\n",
    "\n",
    "    for fname in metrics_fnames:\n",
    "        with open(os.path.join(metrics_save_dir, fname), \"rb\") as f:\n",
    "            metrics = json.load(f)\n",
    "        n_pred_intervals = len(metrics)\n",
    "        print(f\"number of prediction intervals in {fname}: {n_pred_intervals}\")\n",
    "        for pred_interval in metrics:\n",
    "            print(pred_interval)\n",
    "            data = metrics[pred_interval]\n",
    "            for system_name, system_entry in tqdm(\n",
    "                data, desc=f\"Processing {pred_interval}\"\n",
    "            ):\n",
    "                avg_hellinger_accum[\"pred_with_context\"][pred_interval][\n",
    "                    system_name\n",
    "                ].append(system_entry[\"pred_with_context\"][\"avg_hellinger_distance\"])\n",
    "                kld_accum[\"pred_with_context\"][pred_interval][system_name].append(\n",
    "                    system_entry[\"pred_with_context\"][\"kl_divergence\"]\n",
    "                )\n",
    "                corr_gpdim_accum[\"pred_with_context\"][pred_interval][\n",
    "                    system_name\n",
    "                ].append(\n",
    "                    system_entry[\"pred_with_context\"][\"corr_gpdim_pred_with_context\"]\n",
    "                )\n",
    "                gpdim_gt_with_context_accum[\"pred_with_context\"][pred_interval][\n",
    "                    system_name\n",
    "                ].append(system_entry[\"pred_with_context\"][\"gpdim_gt_with_context\"])\n",
    "                gpdim_pred_with_context_accum[\"pred_with_context\"][pred_interval][\n",
    "                    system_name\n",
    "                ].append(system_entry[\"pred_with_context\"][\"gpdim_pred_with_context\"])\n",
    "\n",
    "                pred_time = system_entry[\"prediction_time\"]\n",
    "                prediction_time_accum[system_name].append(pred_time)\n",
    "\n",
    "    # Now, take the mean across all files for each metric, skipping None values\n",
    "    avg_hellinger = {\n",
    "        \"pred_with_context\": defaultdict(dict),\n",
    "    }\n",
    "    kld = {\n",
    "        \"pred_with_context\": defaultdict(dict),\n",
    "    }\n",
    "    corr_gpdim = {\n",
    "        \"pred_with_context\": defaultdict(dict),\n",
    "    }\n",
    "    gpdim_gt_with_context = {\n",
    "        \"pred_with_context\": defaultdict(dict),\n",
    "    }\n",
    "    gpdim_pred_with_context = {\n",
    "        \"pred_with_context\": defaultdict(dict),\n",
    "    }\n",
    "    prediction_time = {}\n",
    "\n",
    "    for key in [\"pred_with_context\"]:\n",
    "        for pred_interval in avg_hellinger_accum[key]:\n",
    "            for system_name, values in avg_hellinger_accum[key][pred_interval].items():\n",
    "                filtered = filter_none(values)\n",
    "                avg_hellinger[key][pred_interval][system_name] = (\n",
    "                    float(np.mean(filtered)) if filtered else None\n",
    "                )\n",
    "        for pred_interval in kld_accum[key]:\n",
    "            for system_name, values in kld_accum[key][pred_interval].items():\n",
    "                filtered = filter_none(values)\n",
    "                kld[key][pred_interval][system_name] = (\n",
    "                    float(np.mean(filtered)) if filtered else None\n",
    "                )\n",
    "        for pred_interval in corr_gpdim_accum[key]:\n",
    "            for system_name, values in corr_gpdim_accum[key][pred_interval].items():\n",
    "                filtered = filter_none(values)\n",
    "                corr_gpdim[key][pred_interval][system_name] = (\n",
    "                    float(np.mean(filtered)) if filtered else None\n",
    "                )\n",
    "        for pred_interval in gpdim_gt_with_context_accum[key]:\n",
    "            for system_name, values in gpdim_gt_with_context_accum[key][\n",
    "                pred_interval\n",
    "            ].items():\n",
    "                filtered = filter_none(values)\n",
    "                gpdim_gt_with_context[key][pred_interval][system_name] = (\n",
    "                    float(np.mean(filtered)) if filtered else None\n",
    "                )\n",
    "        for pred_interval in gpdim_pred_with_context_accum[key]:\n",
    "            for system_name, values in gpdim_pred_with_context_accum[key][\n",
    "                pred_interval\n",
    "            ].items():\n",
    "                filtered = filter_none(values)\n",
    "                gpdim_pred_with_context[key][pred_interval][system_name] = (\n",
    "                    float(np.mean(filtered)) if filtered else None\n",
    "                )\n",
    "\n",
    "    for system_name, times in prediction_time_accum.items():\n",
    "        times_arr = np.array(filter_none(times))\n",
    "        prediction_time[system_name] = (\n",
    "            np.mean(times_arr) if len(times_arr) > 0 else None\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"avg_hellinger\": avg_hellinger,\n",
    "        \"kld\": kld,\n",
    "        \"corr_gpdim\": corr_gpdim,\n",
    "        \"gpdim_gt_with_context\": gpdim_gt_with_context,\n",
    "        \"gpdim_pred_with_context\": gpdim_pred_with_context,\n",
    "        \"prediction_time\": prediction_time,\n",
    "    }\n",
    "\n",
    "\n",
    "# Accumulate metrics for both panda and chronos_sft\n",
    "print(\"Accumulating panda metrics...\")\n",
    "panda_metrics = accumulate_metrics(panda_metrics_fnames, panda_metrics_save_dir)\n",
    "print(\"Accumulating chronos_sft metrics...\")\n",
    "chronos_sft_metrics = accumulate_metrics(\n",
    "    chronos_sft_metrics_fnames, chronos_sft_metrics_save_dir\n",
    ")\n",
    "chronos_zs_metrics = accumulate_metrics(\n",
    "    chronos_zs_metrics_fnames, chronos_zs_metrics_save_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"avg_hellinger\": {\n",
    "        \"panda\": panda_metrics[\"avg_hellinger\"],\n",
    "        \"chronos_sft\": chronos_sft_metrics[\"avg_hellinger\"],\n",
    "        \"chronos_zs\": chronos_zs_metrics[\"avg_hellinger\"],\n",
    "    },\n",
    "    \"kld\": {\n",
    "        \"panda\": panda_metrics[\"kld\"],\n",
    "        \"chronos_sft\": chronos_sft_metrics[\"kld\"],\n",
    "        \"chronos_zs\": chronos_zs_metrics[\"kld\"],\n",
    "    },\n",
    "    \"corr_gpdim\": {\n",
    "        \"panda\": panda_metrics[\"corr_gpdim\"],\n",
    "        \"chronos_sft\": chronos_sft_metrics[\"corr_gpdim\"],\n",
    "        \"chronos_zs\": chronos_zs_metrics[\"corr_gpdim\"],\n",
    "    },\n",
    "    \"gpdim_gt_with_context\": {\n",
    "        \"panda\": panda_metrics[\"gpdim_gt_with_context\"],\n",
    "        \"chronos_sft\": chronos_sft_metrics[\"gpdim_gt_with_context\"],\n",
    "        \"chronos_zs\": chronos_zs_metrics[\"gpdim_gt_with_context\"],\n",
    "    },\n",
    "    \"gpdim_pred_with_context\": {\n",
    "        \"panda\": panda_metrics[\"gpdim_pred_with_context\"],\n",
    "        \"chronos_sft\": chronos_sft_metrics[\"gpdim_pred_with_context\"],\n",
    "        \"chronos_zs\": chronos_zs_metrics[\"gpdim_pred_with_context\"],\n",
    "    },\n",
    "    \"prediction_time\": {\n",
    "        \"panda\": panda_metrics[\"prediction_time\"],\n",
    "        \"chronos_sft\": chronos_sft_metrics[\"prediction_time\"],\n",
    "        \"chronos_zs\": chronos_zs_metrics[\"prediction_time\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_system = list(metrics[\"prediction_time\"][\"panda\"].keys())[0]\n",
    "metrics[\"prediction_time\"][\"panda\"].pop(first_system)\n",
    "metrics[\"prediction_time\"][\"chronos_sft\"].pop(first_system)\n",
    "metrics[\"prediction_time\"][\"chronos_zs\"].pop(first_system)\n",
    "print(metrics[\"prediction_time\"][\"panda\"])\n",
    "print(metrics[\"prediction_time\"][\"chronos_sft\"])\n",
    "print(metrics[\"prediction_time\"][\"chronos_zs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print prediction time mean and std for both panda and chronos_sft\n",
    "\n",
    "for model_name in [\"panda\", \"chronos_sft\", \"chronos_zs\"]:\n",
    "    prediction_times = list(metrics[\"prediction_time\"][model_name].values())\n",
    "    prediction_time_mean = np.mean(prediction_times)\n",
    "    prediction_time_std = np.std(prediction_times)\n",
    "    print(f\"{model_name} prediction time mean:\", prediction_time_mean)\n",
    "    print(f\"{model_name} prediction time std:\", prediction_time_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "values = list(metrics[\"avg_hellinger\"][\"panda\"][\"pred_with_context\"][\"128\"].values())\n",
    "num_nones = sum(v is None for v in values)\n",
    "num_nans = sum(np.isnan(v) for v in values if v is not None)\n",
    "print(f\"Number of None values: {num_nones}\")\n",
    "print(f\"Number of NaN values: {num_nans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_length = \"512\"\n",
    "horizon_name = \"pred_with_context\"\n",
    "\n",
    "\n",
    "def filter_nans(values):\n",
    "    # Convert dict_values to list, filter out None, then filter out NaN\n",
    "    arr = []\n",
    "    for v in list(values):\n",
    "        if v is not None and not (isinstance(v, float) and np.isnan(v)):\n",
    "            arr.append(float(v))\n",
    "    return np.array(arr, dtype=float)\n",
    "\n",
    "\n",
    "avg_full_hellinger_panda = filter_nans(\n",
    "    metrics[\"avg_hellinger\"][\"panda\"][horizon_name][pred_length].values()\n",
    ")\n",
    "avg_full_hellinger_chronos_sft = filter_nans(\n",
    "    metrics[\"avg_hellinger\"][\"chronos_sft\"][horizon_name][pred_length].values()\n",
    ")\n",
    "avg_full_hellinger_chronos_zs = filter_nans(\n",
    "    metrics[\"avg_hellinger\"][\"chronos_zs\"][horizon_name][pred_length].values()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "# Compute common bins for all histograms\n",
    "all_hellinger = np.concatenate(\n",
    "    [\n",
    "        avg_full_hellinger_panda,\n",
    "        avg_full_hellinger_chronos_sft,\n",
    "        avg_full_hellinger_chronos_zs,\n",
    "    ]\n",
    ")\n",
    "bins = np.histogram_bin_edges(all_hellinger, bins=25)\n",
    "\n",
    "alpha_val = 0.6\n",
    "plt.hist(\n",
    "    avg_full_hellinger_panda,\n",
    "    bins=bins,\n",
    "    color=DEFAULT_COLORS[0],\n",
    "    edgecolor=DEFAULT_COLORS[0],\n",
    "    alpha=alpha_val,\n",
    "    histtype=\"stepfilled\",\n",
    "    label=\"Panda\",\n",
    ")\n",
    "plt.hist(\n",
    "    avg_full_hellinger_chronos_sft,\n",
    "    bins=bins,\n",
    "    color=DEFAULT_COLORS[1],\n",
    "    edgecolor=DEFAULT_COLORS[1],\n",
    "    alpha=alpha_val,\n",
    "    histtype=\"stepfilled\",\n",
    "    label=\"Chronos 20M SFT\",\n",
    ")\n",
    "plt.hist(\n",
    "    avg_full_hellinger_chronos_zs,\n",
    "    bins=bins,\n",
    "    color=DEFAULT_COLORS[2] if len(DEFAULT_COLORS) > 2 else \"tab:green\",\n",
    "    edgecolor=DEFAULT_COLORS[2] if len(DEFAULT_COLORS) > 2 else \"tab:green\",\n",
    "    alpha=alpha_val,\n",
    "    histtype=\"stepfilled\",\n",
    "    label=\"Chronos 20M\",\n",
    ")\n",
    "# plt.xlabel(\"Average Hellinger\", fontweight=\"bold\")\n",
    "plt.ylabel(\"Count\", fontweight=\"bold\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\n",
    "    f\"Avg Hellinger Distance ($L_{{\\mathrm{{pred}}}} = {pred_length}$)\",\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    os.path.join(\n",
    "        \"../figures\",\n",
    "        f\"avg_hellinger_distribution_{horizon_name}_{pred_length}.pdf\",\n",
    "    ),\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the difference between Chronos SFT and Panda Hellinger distances\n",
    "hellinger_diff = np.array(avg_full_hellinger_chronos_sft) - np.array(\n",
    "    avg_full_hellinger_panda\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.hist(\n",
    "    hellinger_diff,\n",
    "    bins=30,\n",
    "    color=\"gray\",\n",
    "    edgecolor=\"black\",\n",
    "    alpha=0.7,\n",
    "    histtype=\"stepfilled\",\n",
    ")\n",
    "plt.axvline(\n",
    "    0, color=\"k\", linestyle=\"dotted\", linewidth=1.5\n",
    ")  # Dotted vertical line at zero\n",
    "plt.xlabel(\"Avg Hellinger (Chronos SFT - Panda)\", fontweight=\"bold\")\n",
    "plt.ylabel(\"Count\", fontweight=\"bold\")\n",
    "plt.title(\n",
    "    f\"Difference in Avg Hellinger ($L_{{\\mathrm{{pred}}}} = {pred_length}$)\",\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\n",
    "#     os.path.join(\n",
    "#         \"../figures\",\n",
    "#         f\"avg_hellinger_diff_distribution_{horizon_name}_{pred_length}.pdf\",\n",
    "#     ),\n",
    "#     bbox_inches=\"tight\",\n",
    "# )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_length = \"128\"\n",
    "horizon_name = \"pred_with_context\"\n",
    "full_kld_panda = list(metrics[\"kld\"][\"panda\"][horizon_name][pred_length].values())\n",
    "full_kld_chronos_sft = list(\n",
    "    metrics[\"kld\"][\"chronos_sft\"][horizon_name][pred_length].values()\n",
    ")\n",
    "full_kld_chronos_zs = list(\n",
    "    metrics[\"kld\"][\"chronos_zs\"][horizon_name][pred_length].values()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "# Compute common bins for all histograms, on log scale\n",
    "all_kld = full_kld_panda + full_kld_chronos_sft + full_kld_chronos_zs\n",
    "\n",
    "# Remove zeros and negative values for log scale\n",
    "all_kld_pos = [x for x in all_kld if x > 0]\n",
    "full_kld_panda_pos = [x for x in full_kld_panda if x > 0]\n",
    "full_kld_chronos_sft_pos = [x for x in full_kld_chronos_sft if x > 0]\n",
    "full_kld_chronos_zs_pos = [x for x in full_kld_chronos_zs if x > 0]\n",
    "\n",
    "# Use log-spaced bins\n",
    "if len(all_kld_pos) > 0:\n",
    "    min_kld = min(all_kld_pos)\n",
    "    max_kld = max(all_kld_pos)\n",
    "    bins = np.logspace(np.log10(min_kld), np.log10(max_kld), 20)\n",
    "else:\n",
    "    bins = 25  # fallback\n",
    "    print(\"No positive values found\")\n",
    "\n",
    "alpha_val = 0.6\n",
    "plt.hist(\n",
    "    full_kld_panda_pos,\n",
    "    bins=bins,\n",
    "    color=DEFAULT_COLORS[0],\n",
    "    edgecolor=DEFAULT_COLORS[0],\n",
    "    alpha=alpha_val,\n",
    "    histtype=\"stepfilled\",\n",
    "    label=\"Panda\",\n",
    ")\n",
    "plt.hist(\n",
    "    full_kld_chronos_sft_pos,\n",
    "    bins=bins,\n",
    "    color=DEFAULT_COLORS[1],\n",
    "    edgecolor=DEFAULT_COLORS[1],\n",
    "    alpha=alpha_val,\n",
    "    histtype=\"stepfilled\",\n",
    "    label=\"Chronos 20M SFT\",\n",
    ")\n",
    "plt.hist(\n",
    "    full_kld_chronos_zs_pos,\n",
    "    bins=bins,\n",
    "    color=DEFAULT_COLORS[2] if len(DEFAULT_COLORS) > 2 else \"tab:green\",\n",
    "    edgecolor=DEFAULT_COLORS[2] if len(DEFAULT_COLORS) > 2 else \"tab:green\",\n",
    "    alpha=alpha_val,\n",
    "    histtype=\"stepfilled\",\n",
    "    label=\"Chronos 20M\",\n",
    ")\n",
    "plt.xscale(\"log\")\n",
    "# plt.xlabel(\"Average KL Divergence\", fontweight=\"bold\")\n",
    "plt.ylabel(\"Count\", fontweight=\"bold\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title(\n",
    "    f\"KL Divergence ($L_{{\\mathrm{{pred}}}} = {pred_length}$)\",\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    os.path.join(\n",
    "        \"../figures\",\n",
    "        f\"kld_distribution_{horizon_name}_{pred_length}_log.pdf\",\n",
    "    ),\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the difference between Chronos SFT and Panda KL divergences\n",
    "kld_diff = np.array(full_kld_chronos_sft) - np.array(full_kld_panda)\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.hist(\n",
    "    kld_diff,\n",
    "    bins=30,\n",
    "    color=\"gray\",\n",
    "    edgecolor=\"black\",\n",
    "    alpha=0.7,\n",
    "    histtype=\"stepfilled\",\n",
    ")\n",
    "plt.axvline(\n",
    "    0, color=\"k\", linestyle=\"dotted\", linewidth=1.5\n",
    ")  # Dotted vertical line at zero\n",
    "plt.xlabel(\"$D_{{KL}}$ (Chronos SFT - Panda)\", fontweight=\"bold\")\n",
    "plt.ylabel(\"Count\", fontweight=\"bold\")\n",
    "plt.title(\n",
    "    f\"Difference in $D_{{KL}}$ ($L_{{\\mathrm{{pred}}}} = {pred_length}$)\",\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\n",
    "#     os.path.join(\n",
    "#         \"../figures\",\n",
    "#         f\"avg_kld_diff_distribution_{horizon_name}_{pred_length}.pdf\",\n",
    "#     ),\n",
    "#     bbox_inches=\"tight\",\n",
    "# )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_for_models(\n",
    "    metrics: dict,\n",
    "    models: list[str],\n",
    "    pred_length: int,\n",
    "    horizon_name: str = \"pred_with_context\",\n",
    "    metric_name: str = \"kld\",\n",
    ") -> dict[str, np.ndarray]:\n",
    "    metrics_dict = {}\n",
    "    for model in models:\n",
    "        values = metrics[metric_name][model][horizon_name][str(pred_length)].values()\n",
    "        metrics_dict[model] = np.array(list(filter(lambda x: x > 0, values)))\n",
    "    return metrics_dict\n",
    "\n",
    "\n",
    "models = [\"panda\", \"chronos_sft\", \"chronos_zs\"]\n",
    "pred_lengths = [128, 256, 512]\n",
    "\n",
    "klds_by_pred_length = {\n",
    "    pl: get_metrics_for_models(metrics, models, pl) for pl in pred_lengths\n",
    "}\n",
    "\n",
    "for pl, klds in klds_by_pred_length.items():\n",
    "    print(f\"Pred length: {pl}\")\n",
    "    for model, kld in klds.items():\n",
    "        print(f\"\\t{model} KLD mu: {kld.mean()}, std: {kld.std()}\")\n",
    "\n",
    "    panda_mean = klds[\"panda\"].mean()\n",
    "    baseline_means = {model: arr.mean() for model, arr in klds.items() if model != \"panda\"}\n",
    "    best_baseline_model = min(baseline_means, key=baseline_means.get)\n",
    "    best_baseline_mean = baseline_means[best_baseline_model]\n",
    "    pct_diff = 100 * (panda_mean - best_baseline_mean) / best_baseline_mean\n",
    "    sign = \"+\" if pct_diff < 0 else \"-\"\n",
    "    print(f\"\\tPct improvement: {sign}{np.abs(pct_diff):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_kld_diff = np.mean(np.array(full_kld_chronos_sft) - np.array(full_kld_panda))\n",
    "std_kld_diff = np.std(np.array(full_kld_chronos_sft) - np.array(full_kld_panda))\n",
    "print(f\"Mean KL diff: {mean_kld_diff:.4f}, Std KL diff: {std_kld_diff:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_kld_diff = np.mean(np.array(full_kld_chronos_zs) - np.array(full_kld_chronos_sft))\n",
    "std_kld_diff = np.std(np.array(full_kld_chronos_zs) - np.array(full_kld_chronos_sft))\n",
    "print(f\"Mean KL diff: {mean_kld_diff:.4f}, Std KL diff: {std_kld_diff:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_kld_diff = np.mean(np.array(full_kld_chronos_zs) - np.array(full_kld_panda))\n",
    "std_kld_diff = np.std(np.array(full_kld_chronos_zs) - np.array(full_kld_panda))\n",
    "print(f\"Mean KL diff: {mean_kld_diff:.4f}, Std KL diff: {std_kld_diff:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lengths = [\"128\", \"256\", \"512\"]\n",
    "horizon_name = \"pred_with_context\"\n",
    "pairs = [\n",
    "    (\"Chronos SFT - Panda\", \"chronos_sft\", \"panda\"),\n",
    "    (\"Chronos ZS - Chronos SFT\", \"chronos_zs\", \"chronos_sft\"),\n",
    "    (\"Chronos ZS - Panda\", \"chronos_zs\", \"panda\"),\n",
    "]\n",
    "for pred_length in pred_lengths:\n",
    "    klds = {\n",
    "        key: np.array(list(metrics[\"kld\"][key][horizon_name][pred_length].values()))\n",
    "        for _, key, _ in pairs\n",
    "    }\n",
    "    klds[\"panda\"] = np.array(\n",
    "        list(metrics[\"kld\"][\"panda\"][horizon_name][pred_length].values())\n",
    "    )\n",
    "    for label, key1, key2 in pairs:\n",
    "        diff = klds[key1] - klds[key2]\n",
    "        print(\n",
    "            f\"Mean KL diff ({label}): {diff.mean():.4f}, Std KL diff: {diff.std():.4f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_name = \"pred_with_context\"\n",
    "for pred_length in pred_lengths:\n",
    "    hells = {\n",
    "        key: np.array(\n",
    "            list(metrics[\"avg_hellinger\"][key][horizon_name][pred_length].values())\n",
    "        )\n",
    "        for _, key, _ in pairs\n",
    "    }\n",
    "    hells[\"panda\"] = np.array(\n",
    "        list(metrics[\"avg_hellinger\"][\"panda\"][horizon_name][pred_length].values())\n",
    "    )\n",
    "    for label, key1, key2 in pairs:\n",
    "        diff = hells[key1] - hells[key2]\n",
    "        diff_no_nan = diff[~np.isnan(diff)]\n",
    "        print(\n",
    "            f\"Mean avg_hellinger diff ({label}): {diff_no_nan.mean():.2f}, Std avg_hellinger diff: {diff_no_nan.std():.2f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_length = \"256\"\n",
    "horizon_name = \"pred_with_context\"\n",
    "\n",
    "\n",
    "def filter_nans(values):\n",
    "    # Convert dict_values to list, filter out None, then filter out NaN\n",
    "    arr = []\n",
    "    for v in list(values):\n",
    "        if v is not None and not (isinstance(v, float) and np.isnan(v)):\n",
    "            arr.append(float(v))\n",
    "    return np.array(arr, dtype=float)\n",
    "\n",
    "\n",
    "avg_full_hellinger_panda = filter_nans(\n",
    "    metrics[\"corr_gpdim\"][\"panda\"][horizon_name][pred_length].values()\n",
    ")\n",
    "avg_full_hellinger_chronos_sft = filter_nans(\n",
    "    metrics[\"corr_gpdim\"][\"chronos_sft\"][horizon_name][pred_length].values()\n",
    ")\n",
    "avg_full_hellinger_chronos_zs = filter_nans(\n",
    "    metrics[\"corr_gpdim\"][\"chronos_zs\"][horizon_name][pred_length].values()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "# Compute common bins for all histograms\n",
    "all_hellinger = np.concatenate(\n",
    "    [\n",
    "        avg_full_hellinger_panda,\n",
    "        avg_full_hellinger_chronos_sft,\n",
    "        avg_full_hellinger_chronos_zs,\n",
    "    ]\n",
    ")\n",
    "bins = np.histogram_bin_edges(all_hellinger, bins=25)\n",
    "\n",
    "alpha_val = 0.6\n",
    "plt.hist(\n",
    "    avg_full_hellinger_panda,\n",
    "    bins=bins,\n",
    "    color=DEFAULT_COLORS[0],\n",
    "    edgecolor=DEFAULT_COLORS[0],\n",
    "    alpha=alpha_val,\n",
    "    histtype=\"stepfilled\",\n",
    "    label=\"Panda\",\n",
    ")\n",
    "plt.hist(\n",
    "    avg_full_hellinger_chronos_sft,\n",
    "    bins=bins,\n",
    "    color=DEFAULT_COLORS[1],\n",
    "    edgecolor=DEFAULT_COLORS[1],\n",
    "    alpha=alpha_val,\n",
    "    histtype=\"stepfilled\",\n",
    "    label=\"Chronos 20M SFT\",\n",
    ")\n",
    "plt.hist(\n",
    "    avg_full_hellinger_chronos_zs,\n",
    "    bins=bins,\n",
    "    color=DEFAULT_COLORS[2] if len(DEFAULT_COLORS) > 2 else \"tab:green\",\n",
    "    edgecolor=DEFAULT_COLORS[2] if len(DEFAULT_COLORS) > 2 else \"tab:green\",\n",
    "    alpha=alpha_val,\n",
    "    histtype=\"stepfilled\",\n",
    "    label=\"Chronos 20M\",\n",
    ")\n",
    "# plt.xlabel(\"Average Hellinger\", fontweight=\"bold\")\n",
    "plt.ylabel(\"Count\", fontweight=\"bold\")\n",
    "plt.yscale(\"log\")  # Set y-axis to log scale\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\n",
    "    f\"Cross-Correlation GP Dim ($L_{{\\mathrm{{pred}}}} = {pred_length}$)\",\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    os.path.join(\n",
    "        \"../figures\",\n",
    "        f\"corr_gpdim_distribution_{horizon_name}_{pred_length}_log.pdf\",\n",
    "    ),\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the prediction interval (pred_length) of 512\n",
    "pred_length = \"128\"\n",
    "model_type = \"chronos_sft\"\n",
    "\n",
    "# Get the dictionaries for gpdim_gt_with_context and gpdim_pred_with_context at pred_length for model_type\n",
    "gpdim_gtcontext_dict = metrics[\"gpdim_gt_with_context\"][model_type].get(pred_length, {})\n",
    "gpdim_predcontext_dict = metrics[\"gpdim_pred_with_context\"][model_type].get(\n",
    "    pred_length, {}\n",
    ")\n",
    "\n",
    "print(gpdim_gtcontext_dict)\n",
    "print(gpdim_predcontext_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[\"gpdim_gt_with_context\"][\"chronos_sft\"][\"pred_with_context\"][\"128\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import ScalarFormatter\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Choose the prediction interval (pred_length) of 512\n",
    "pred_length = \"512\"\n",
    "model_type = \"panda\"\n",
    "horizon_name = \"pred_with_context\"\n",
    "\n",
    "# Get the dictionaries for gpdim_gt_with_context and gpdim_pred_with_context at pred_length for model_type\n",
    "gpdim_gtcontext_dict = metrics[\"gpdim_gt_with_context\"][model_type][horizon_name][\n",
    "    pred_length\n",
    "]\n",
    "gpdim_predcontext_dict = metrics[\"gpdim_pred_with_context\"][model_type][horizon_name][\n",
    "    pred_length\n",
    "]\n",
    "\n",
    "# Find the intersection of system names present in both\n",
    "system_names = set(gpdim_gtcontext_dict.keys()) & set(gpdim_predcontext_dict.keys())\n",
    "\n",
    "# Prepare x and y data for scatter plot\n",
    "x = [gpdim_gtcontext_dict[sys] for sys in system_names]\n",
    "y = [gpdim_predcontext_dict[sys] for sys in system_names]\n",
    "\n",
    "# Compute R^2 score\n",
    "if len(x) > 0 and len(y) > 0:\n",
    "    r2 = r2_score(x, y)\n",
    "else:\n",
    "    r2 = float(\"nan\")\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.scatter(x, y, color=\"black\", s=5, alpha=0.1, label=None)\n",
    "plt.xlabel(\"Context + Ground Truth\", fontweight=\"bold\")\n",
    "plt.ylabel(\"Context + Prediction\", fontweight=\"bold\")\n",
    "plt.title(rf\"GP Dim ($L_{{\\mathrm{{pred}}}} = {pred_length}$)\", fontweight=\"bold\")\n",
    "\n",
    "# Prepare handles and labels for legend\n",
    "handles = []\n",
    "labels = []\n",
    "\n",
    "# Plot y=x line in red dashed, but do NOT add to legend yet\n",
    "y_eq_x_min = min(x + y)\n",
    "y_eq_x_max = max(x + y)\n",
    "(h1,) = plt.plot(\n",
    "    [y_eq_x_min, y_eq_x_max], [y_eq_x_min, y_eq_x_max], \"r--\", label=r\"$y=x$\"\n",
    ")\n",
    "\n",
    "# Plot line of best fit as solid red line and prepare equation+R2 for legend\n",
    "eqn_r2_label = None\n",
    "if len(x) > 1 and len(y) > 1:\n",
    "    # Fit line: y = m*x + b\n",
    "    m, b = np.polyfit(x, y, 1)\n",
    "    x_fit = np.array([y_eq_x_min, y_eq_x_max])\n",
    "    y_fit = m * x_fit + b\n",
    "    # Format equation for label (to be shown in legend with R^2)\n",
    "    if abs(b) < 1e-10:\n",
    "        eqn_str = rf\"$y = {m:.2f}x$\"\n",
    "    else:\n",
    "        sign = \"+\" if b >= 0 else \"-\"\n",
    "        eqn_str = rf\"$y = {m:.2f}x {sign} {abs(b):.2f}$\"\n",
    "    if not (r2 != r2):  # check for nan\n",
    "        eqn_r2_label = rf\"{eqn_str}  $(R^2 = {r2:.3f})$\"\n",
    "    else:\n",
    "        eqn_r2_label = eqn_str\n",
    "    (h2,) = plt.plot(\n",
    "        x_fit, y_fit, color=\"red\", linestyle=\"-\", linewidth=1.5, label=eqn_r2_label\n",
    "    )\n",
    "    # Add best fit line first, then y=x line, to put y=x below in legend\n",
    "    handles.append(h2)\n",
    "    labels.append(eqn_r2_label)\n",
    "    handles.append(h1)\n",
    "    labels.append(r\"$y=x$\")\n",
    "else:\n",
    "    # If no best fit, just add y=x\n",
    "    handles.append(h1)\n",
    "    labels.append(r\"$y=x$\")\n",
    "\n",
    "# Show legend in lower right, showing both lines and their labels\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "ax.ticklabel_format(style=\"sci\", axis=\"both\", scilimits=(0, 0))\n",
    "\n",
    "if len(handles) > 0:\n",
    "    ax.legend(\n",
    "        handles=handles, labels=labels, loc=\"lower right\", fontsize=8, frameon=True\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    os.path.join(\n",
    "        \"../figures\",\n",
    "        f\"gpdim_gtcontext_predcontext_{pred_length}_{model_type}.pdf\",\n",
    "    ),\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
