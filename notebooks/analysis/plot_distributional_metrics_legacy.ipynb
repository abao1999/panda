{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from panda.utils.plot_utils import apply_custom_style\n",
    "\n",
    "apply_custom_style(\"../../config/plotting.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_save_dir = os.path.join(\"../../figures\", \"eval_metrics\")\n",
    "os.makedirs(fig_save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_COLORS = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = os.getenv(\"WORK\", \"\")\n",
    "DATA_DIR = os.path.join(WORK_DIR, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_chronos_deterministic = False\n",
    "if use_chronos_deterministic:\n",
    "    chronos_dirname = \"chronos\"\n",
    "else:\n",
    "    chronos_dirname = \"chronos_nondeterministic\"\n",
    "\n",
    "\n",
    "def get_sorted_metric_fnames(save_dir):\n",
    "    fnames = [f for f in os.listdir(save_dir) if f.endswith(\".json\") and \"distributional_metrics\"]\n",
    "\n",
    "    def extract_window(fname):\n",
    "        m = re.search(r\"window-(\\d+)\", fname)\n",
    "        return int(m.group(1)) if m else float(\"inf\")\n",
    "\n",
    "    return sorted(fnames, key=extract_window)\n",
    "\n",
    "\n",
    "panda_metrics_save_dir = f\"{WORK_DIR}/eval_results_old/panda/pft_chattn_emb_w_poly-0/test_zeroshot/metrics_run1\"\n",
    "# NOTE: we also have for chronos_nondeterministic, replace \"chronos\" with \"chronos_nondeterministic\" in the paths below\n",
    "chronos_sft_metrics_save_dir = (\n",
    "    f\"{WORK_DIR}/eval_results_old/{chronos_dirname}/chronos_t5_mini_ft-0/test_zeroshot/metrics_run1\"\n",
    ")\n",
    "chronos_zs_metrics_save_dir = (\n",
    "    f\"{WORK_DIR}/eval_results_old/{chronos_dirname}/chronos_mini_zeroshot/test_zeroshot/metrics_run1\"\n",
    ")\n",
    "\n",
    "panda_metrics_fnames = get_sorted_metric_fnames(panda_metrics_save_dir)\n",
    "chronos_sft_metrics_fnames = get_sorted_metric_fnames(chronos_sft_metrics_save_dir)\n",
    "chronos_zs_metrics_fnames = get_sorted_metric_fnames(chronos_zs_metrics_save_dir)\n",
    "\n",
    "print(f\"Found {len(panda_metrics_fnames)} panda metrics files: {panda_metrics_fnames}\")\n",
    "print(f\"Found {len(chronos_sft_metrics_fnames)} chronos sft metrics files: {chronos_sft_metrics_fnames}\")\n",
    "print(f\"Found {len(chronos_zs_metrics_fnames)} chronos zs metrics files: {chronos_zs_metrics_fnames}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_fpath = os.path.join(chronos_sft_metrics_save_dir, chronos_zs_metrics_fnames[0])\n",
    "with open(metrics_fpath, \"rb\") as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "print(metrics.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For accumulating values across all files, for both panda and chronos_sft metrics\n",
    "\n",
    "\n",
    "def filter_none(values):\n",
    "    \"\"\"Remove None values from a list.\"\"\"\n",
    "    return [v for v in values if v is not None]\n",
    "\n",
    "\n",
    "def accumulate_metrics(metrics_fnames, metrics_save_dir):\n",
    "    avg_hellinger_accum = {\n",
    "        \"pred_horizon\": defaultdict(lambda: defaultdict(list)),\n",
    "        \"full\": defaultdict(lambda: defaultdict(list)),\n",
    "    }\n",
    "    kld_accum = {\n",
    "        \"pred_horizon\": defaultdict(lambda: defaultdict(list)),\n",
    "        \"full\": defaultdict(lambda: defaultdict(list)),\n",
    "    }\n",
    "    prediction_time_accum = defaultdict(list)\n",
    "\n",
    "    for fname in metrics_fnames:\n",
    "        with open(os.path.join(metrics_save_dir, fname), \"rb\") as f:\n",
    "            metrics = json.load(f)\n",
    "        n_pred_intervals = len(metrics)\n",
    "        print(f\"number of prediction intervals in {fname}: {n_pred_intervals}\")\n",
    "        for pred_interval in metrics:\n",
    "            print(pred_interval)\n",
    "            data = metrics[pred_interval]\n",
    "            for system_name, system_entry in tqdm(data, desc=f\"Processing {pred_interval}\"):\n",
    "                avg_hellinger_accum[\"pred_horizon\"][pred_interval][system_name].append(\n",
    "                    system_entry[\"prediction_horizon\"][\"avg_hellinger_distance\"]\n",
    "                )\n",
    "                avg_hellinger_accum[\"full\"][pred_interval][system_name].append(\n",
    "                    system_entry[\"full_trajectory\"][\"avg_hellinger_distance\"]\n",
    "                )\n",
    "                kld_accum[\"pred_horizon\"][pred_interval][system_name].append(\n",
    "                    system_entry[\"prediction_horizon\"][\"kl_divergence\"]\n",
    "                )\n",
    "                kld_accum[\"full\"][pred_interval][system_name].append(system_entry[\"full_trajectory\"][\"kl_divergence\"])\n",
    "                pred_time = system_entry[\"prediction_time\"]\n",
    "                prediction_time_accum[system_name].append(pred_time)\n",
    "\n",
    "    # Now, take the mean across all files for each metric, skipping None values\n",
    "    avg_hellinger = {\n",
    "        \"pred_horizon\": defaultdict(dict),\n",
    "        \"full\": defaultdict(dict),\n",
    "    }\n",
    "    kld = {\n",
    "        \"pred_horizon\": defaultdict(dict),\n",
    "        \"full\": defaultdict(dict),\n",
    "    }\n",
    "    prediction_time = {}\n",
    "\n",
    "    for key in [\"pred_horizon\", \"full\"]:\n",
    "        for pred_interval in avg_hellinger_accum[key]:\n",
    "            for system_name, values in avg_hellinger_accum[key][pred_interval].items():\n",
    "                filtered = filter_none(values)\n",
    "                avg_hellinger[key][pred_interval][system_name] = float(np.mean(filtered)) if filtered else None\n",
    "        for pred_interval in kld_accum[key]:\n",
    "            for system_name, values in kld_accum[key][pred_interval].items():\n",
    "                filtered = filter_none(values)\n",
    "                kld[key][pred_interval][system_name] = float(np.mean(filtered)) if filtered else None\n",
    "\n",
    "    for system_name, times in prediction_time_accum.items():\n",
    "        times_arr = np.array(filter_none(times))\n",
    "        prediction_time[system_name] = np.mean(times_arr) if len(times_arr) > 0 else None\n",
    "\n",
    "    return {\n",
    "        \"avg_hellinger\": avg_hellinger,\n",
    "        \"kld\": kld,\n",
    "        \"prediction_time\": prediction_time,\n",
    "    }\n",
    "\n",
    "\n",
    "# Accumulate metrics for both panda and chronos_sft\n",
    "print(\"Accumulating panda metrics...\")\n",
    "panda_metrics = accumulate_metrics(panda_metrics_fnames, panda_metrics_save_dir)\n",
    "print(\"Accumulating chronos_sft metrics...\")\n",
    "chronos_sft_metrics = accumulate_metrics(chronos_sft_metrics_fnames, chronos_sft_metrics_save_dir)\n",
    "chronos_zs_metrics = accumulate_metrics(chronos_zs_metrics_fnames, chronos_zs_metrics_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"panda\", \"chronos_sft\", \"chronos_zs\"]\n",
    "metrics = {k: {m: eval(f\"{m}_metrics\")[k] for m in models} for k in [\"avg_hellinger\", \"kld\", \"prediction_time\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[\"avg_hellinger\"][\"panda\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_length = \"512\"\n",
    "horizon_name = \"pred_horizon\"\n",
    "\n",
    "show_chronos_zs = False\n",
    "\n",
    "\n",
    "def filter_nans(values):\n",
    "    arr = [float(v) for v in values if v is not None and not (isinstance(v, float) and np.isnan(v))]\n",
    "    return np.array(arr, dtype=float)\n",
    "\n",
    "\n",
    "avg_hellinger = {\n",
    "    \"Panda\": filter_nans(metrics[\"avg_hellinger\"][\"panda\"][horizon_name][pred_length].values()),\n",
    "    \"Chronos 20M SFT\": filter_nans(metrics[\"avg_hellinger\"][\"chronos_sft\"][horizon_name][pred_length].values()),\n",
    "    \"Chronos 20M\": filter_nans(metrics[\"avg_hellinger\"][\"chronos_zs\"][horizon_name][pred_length].values()),\n",
    "}\n",
    "\n",
    "num_bins = 50\n",
    "plt.figure(figsize=(4, 4))\n",
    "all_hellinger = np.concatenate(list(avg_hellinger.values()))\n",
    "print(f\"min hellinger: {all_hellinger.min()}, max hellinger: {all_hellinger.max()}\")\n",
    "bins = np.histogram_bin_edges(all_hellinger, bins=num_bins)\n",
    "alpha_val = 0.6\n",
    "\n",
    "for i, (label, vals) in enumerate(avg_hellinger.items()):\n",
    "    if not show_chronos_zs and label == \"Chronos 20M\":\n",
    "        continue\n",
    "    color = DEFAULT_COLORS[i] if i < len(DEFAULT_COLORS) else f\"tab:{['blue', 'orange', 'green'][i % 3]}\"\n",
    "    plt.hist(\n",
    "        vals,\n",
    "        bins=bins,\n",
    "        color=color,\n",
    "        edgecolor=color,\n",
    "        alpha=alpha_val,\n",
    "        zorder=10 - i,\n",
    "        histtype=\"stepfilled\",\n",
    "        label=label,\n",
    "    )\n",
    "\n",
    "plt.ylabel(\"Count\", fontweight=\"bold\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(f\"Avg Hellinger Distance ($L_{{\\\\mathrm{{pred}}}} = {pred_length}$)\", fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    os.path.join(fig_save_dir, f\"avg_hellinger_distribution_{horizon_name}_{pred_length}.pdf\"),\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[\"kld\"][\"panda\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_length = \"512\"\n",
    "horizon_name = \"full\"\n",
    "\n",
    "show_chronos_zs = False\n",
    "\n",
    "\n",
    "# Extract and filter positive KL divergence values\n",
    "def pos_vals(vals):\n",
    "    return [x for x in vals if x > 0]\n",
    "\n",
    "\n",
    "kld_dict = {\n",
    "    \"Panda\": pos_vals(metrics[\"kld\"][\"panda\"][horizon_name][pred_length].values()),\n",
    "    \"Chronos 20M SFT\": pos_vals(metrics[\"kld\"][\"chronos_sft\"][horizon_name][pred_length].values()),\n",
    "    \"Chronos 20M\": pos_vals(metrics[\"kld\"][\"chronos_zs\"][horizon_name][pred_length].values()),\n",
    "}\n",
    "\n",
    "all_kld_pos = np.concatenate(list(kld_dict.values()))\n",
    "num_bins = 50\n",
    "if len(all_kld_pos) > 0:\n",
    "    bins = np.linspace(all_kld_pos.min(), all_kld_pos.max(), num_bins)\n",
    "else:\n",
    "    bins = num_bins\n",
    "    print(\"No positive values found\")\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "alpha_val = 0.6\n",
    "for i, (label, vals) in enumerate(kld_dict.items()):\n",
    "    if not show_chronos_zs and label == \"Chronos 20M\":\n",
    "        continue\n",
    "    color = DEFAULT_COLORS[i] if i < len(DEFAULT_COLORS) else f\"tab:{['blue', 'orange', 'green'][i % 3]}\"\n",
    "    plt.hist(\n",
    "        vals,\n",
    "        bins=bins,\n",
    "        color=color,\n",
    "        edgecolor=color,\n",
    "        alpha=alpha_val,\n",
    "        histtype=\"stepfilled\",\n",
    "        label=label,\n",
    "        zorder=10 - i,\n",
    "    )\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"Count\", fontweight=\"bold\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(f\"KL Divergence ($L_{{\\\\mathrm{{pred}}}} = {pred_length}$)\", fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(fig_save_dir, f\"kld_distribution_{horizon_name}_{pred_length}_log.pdf\"), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_length = \"512\"\n",
    "horizon_name = \"full\"\n",
    "\n",
    "full_kld_panda = list(metrics[\"kld\"][\"panda\"][horizon_name][pred_length].values())\n",
    "full_kld_chronos_sft = list(metrics[\"kld\"][\"chronos_sft\"][horizon_name][pred_length].values())\n",
    "full_kld_chronos_zs = list(metrics[\"kld\"][\"chronos_zs\"][horizon_name][pred_length].values())\n",
    "\n",
    "# Plot difference between Chronos SFT and Panda KL divergences\n",
    "kld_diff = np.array(full_kld_chronos_sft) - np.array(full_kld_panda)\n",
    "# kld_diff = np.array(full_kld_panda) - np.array(full_kld_chronos_sft)\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.hist(kld_diff, bins=30, color=\"gray\", edgecolor=\"black\", alpha=0.7, histtype=\"stepfilled\")\n",
    "plt.axvline(0, color=\"k\", linestyle=\"dotted\", linewidth=1.5)\n",
    "plt.xlabel(\"$D_{{KL}}$ (Chronos SFT - Panda)\", fontweight=\"bold\")\n",
    "plt.ylabel(\"Count\", fontweight=\"bold\")\n",
    "plt.title(f\"Difference in $D_{{KL}}$ ($L_{{\\\\mathrm{{pred}}}} = {pred_length}$)\", fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_kld_diff = np.mean(np.array(full_kld_chronos_sft) - np.array(full_kld_panda))\n",
    "std_kld_diff = np.std(np.array(full_kld_chronos_sft) - np.array(full_kld_panda))\n",
    "print(f\"Mean KL diff: {mean_kld_diff:.4f}, Std KL diff: {std_kld_diff:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_kld_diff = np.mean(np.array(full_kld_chronos_zs) - np.array(full_kld_chronos_sft))\n",
    "std_kld_diff = np.std(np.array(full_kld_chronos_zs) - np.array(full_kld_chronos_sft))\n",
    "print(f\"Mean KL diff: {mean_kld_diff:.4f}, Std KL diff: {std_kld_diff:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_kld_diff = np.mean(np.array(full_kld_chronos_zs) - np.array(full_kld_panda))\n",
    "std_kld_diff = np.std(np.array(full_kld_chronos_zs) - np.array(full_kld_panda))\n",
    "print(f\"Mean KL diff: {mean_kld_diff:.4f}, Std KL diff: {std_kld_diff:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lengths = [\"128\", \"256\", \"512\"]\n",
    "horizon_name = \"full\"\n",
    "pairs = [\n",
    "    (\"Chronos SFT - Panda\", \"chronos_sft\", \"panda\"),\n",
    "    (\"Chronos ZS - Chronos SFT\", \"chronos_zs\", \"chronos_sft\"),\n",
    "    (\"Chronos ZS - Panda\", \"chronos_zs\", \"panda\"),\n",
    "]\n",
    "for pred_length in pred_lengths:\n",
    "    klds = {key: np.array(list(metrics[\"kld\"][key][horizon_name][pred_length].values())) for _, key, _ in pairs}\n",
    "    klds[\"panda\"] = np.array(list(metrics[\"kld\"][\"panda\"][horizon_name][pred_length].values()))\n",
    "    for label, key1, key2 in pairs:\n",
    "        diff = klds[key1] - klds[key2]\n",
    "        print(f\"Mean KL diff ({label}): {diff.mean():.4f}, Std KL diff: {diff.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lengths = [\"128\", \"256\", \"512\"]\n",
    "horizon_name = \"pred_horizon\"\n",
    "for pred_length in pred_lengths:\n",
    "    hells = {\n",
    "        key: np.array(list(metrics[\"avg_hellinger\"][key][horizon_name][pred_length].values())) for _, key, _ in pairs\n",
    "    }\n",
    "    hells[\"panda\"] = np.array(list(metrics[\"avg_hellinger\"][\"panda\"][horizon_name][pred_length].values()))\n",
    "    for label, key1, key2 in pairs:\n",
    "        diff = hells[key1] - hells[key2]\n",
    "        print(f\"Mean avg_hellinger diff ({label}): {diff.mean():.2f}, Std avg_hellinger diff: {diff.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_name = \"pred_horizon\"\n",
    "print(f\"horizon_name: {horizon_name}\")\n",
    "print(\"KL Divergence\")\n",
    "for model_key in [\"panda\", \"chronos_sft\", \"chronos_zs\"]:\n",
    "    print(f\"Model: {model_key}\")\n",
    "    for pred_length in pred_lengths:\n",
    "        kld_values = np.array(list(metrics[\"kld\"][model_key][horizon_name][pred_length].values()))\n",
    "        kld_values_no_nan = kld_values[~np.isnan(kld_values)]\n",
    "        mean_kld = kld_values_no_nan.mean()\n",
    "        std_kld = kld_values_no_nan.std()\n",
    "        print(f\"  Prediction length {pred_length}: mean kld = {mean_kld:.4f}, std kld = {std_kld:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_name = \"full\"\n",
    "print(f\"horizon_name: {horizon_name}\")\n",
    "print(\"KL Divergence\")\n",
    "for model_key in [\"panda\", \"chronos_sft\", \"chronos_zs\"]:\n",
    "    print(f\"Model: {model_key}\")\n",
    "    for pred_length in pred_lengths:\n",
    "        kld_values = np.array(list(metrics[\"kld\"][model_key][horizon_name][pred_length].values()))\n",
    "        kld_values_no_nan = kld_values[~np.isnan(kld_values)]\n",
    "        mean_kld = kld_values_no_nan.mean()\n",
    "        std_kld = kld_values_no_nan.std()\n",
    "        print(f\"  Prediction length {pred_length}: mean kld = {mean_kld:.4f}, std kld = {std_kld:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
