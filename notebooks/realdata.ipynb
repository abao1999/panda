{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from typing import Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from dysts.metrics import compute_metrics\n",
    "from scipy.io import loadmat\n",
    "from tqdm import tqdm\n",
    "\n",
    "from panda.chronos.pipeline import ChronosPipeline\n",
    "from panda.patchtst.pipeline import PatchTSTPipeline\n",
    "from panda.utils.data_utils import safe_standardize\n",
    "from panda.utils.plot_utils import DEFAULT_MARKERS, apply_custom_style\n",
    "\n",
    "apply_custom_style(\"../config/plotting.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK = os.environ.get(\"WORK\", \"\")\n",
    "base_dir = f\"{WORK}/physics-datasets\"\n",
    "DEFAULT_COLORS = list(plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"mse\", \"mae\", \"smape\"]\n",
    "\n",
    "fig_dir = \"../figures/realdata\"\n",
    "os.makedirs(fig_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_name = \"pft_chattn_emb_w_poly-0\"  # NOTE: this is still the best\n",
    "run_name = \"pft_polyfeats_fromscratch_repro-0\"\n",
    "\n",
    "pft_model = PatchTSTPipeline.from_pretrained(\n",
    "    mode=\"predict\",\n",
    "    pretrain_path=f\"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/{run_name}/checkpoint-final\",\n",
    "    device_map=\"cuda:2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"chronos_t5_mini_ft-0\"\n",
    "chronos_ft = ChronosPipeline.from_pretrained(\n",
    "    f\"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/{run_name}/checkpoint-final\",\n",
    "    device_map=\"cuda:3\",\n",
    "    torch_dtype=torch.float32,\n",
    ")\n",
    "\n",
    "chronos_ft_kwargs = {\n",
    "    \"transpose\": True,\n",
    "    \"limit_prediction_length\": False,\n",
    "    \"num_samples\": 1,\n",
    "    \"deterministic\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"amazon/chronos-t5-mini\"\n",
    "chronos_zs = ChronosPipeline.from_pretrained(run_name, device_map=\"cuda:4\", torch_dtype=torch.float32)\n",
    "\n",
    "chronos_zs_kwargs = {\n",
    "    \"transpose\": True,\n",
    "    \"limit_prediction_length\": False,\n",
    "    \"num_samples\": 1,\n",
    "    \"deterministic\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast and Plot Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(\n",
    "    model,\n",
    "    context: np.ndarray,\n",
    "    prediction_length: int,\n",
    "    transpose: bool = False,\n",
    "    standardize: bool = True,\n",
    "    differenced: bool = False,\n",
    "    **kwargs,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: The model to use for forecasting.\n",
    "        context: The context to forecast (n_timesteps, n_features)\n",
    "        context_length: The length of the context.\n",
    "        prediction_length: The length of the prediction.\n",
    "        transpose: Whether to transpose the data.\n",
    "\n",
    "    Returns:\n",
    "        The forecasted data (prediction_length, n_features)\n",
    "    \"\"\"\n",
    "    preprocessed_context = context.copy()\n",
    "\n",
    "    if differenced:\n",
    "        differenced_context = np.diff(preprocessed_context, axis=0)\n",
    "        preprocessed_context = differenced_context.copy()\n",
    "    if standardize:\n",
    "        preprocessed_context = safe_standardize(preprocessed_context, axis=0)\n",
    "\n",
    "    context_tensor = torch.from_numpy(preprocessed_context.T if transpose else preprocessed_context).float()\n",
    "    pred = model.predict(context_tensor, prediction_length, verbose=False, **kwargs).squeeze().cpu().numpy()\n",
    "    if transpose:\n",
    "        pred = pred.T\n",
    "\n",
    "    if standardize:\n",
    "        pred = safe_standardize(\n",
    "            pred,\n",
    "            axis=0,\n",
    "            context=differenced_context if differenced else context,\n",
    "            denormalize=True,\n",
    "        )\n",
    "    if differenced:\n",
    "        pred = np.cumsum(pred, axis=0) + context[-1]\n",
    "\n",
    "    # prediction length may be shorter than model output length\n",
    "    return pred[:prediction_length, :] if pred.ndim == 2 else pred[:prediction_length]\n",
    "\n",
    "\n",
    "def compute_rollout_metrics(\n",
    "    model,\n",
    "    data: np.ndarray,\n",
    "    context_length: int,\n",
    "    prediction_length: int,\n",
    "    starts: np.ndarray | list[int] | None = None,\n",
    "    num_windows: int | None = None,\n",
    "    step: int = 64,\n",
    "    metrics: list[str] = [\"mse\", \"mae\", \"smape\"],\n",
    "    **kwargs,\n",
    ") -> tuple[\n",
    "    dict[str, np.ndarray],\n",
    "    dict[str, np.ndarray],\n",
    "    np.ndarray | list[int],\n",
    "    list[np.ndarray],\n",
    "]:\n",
    "    if starts is not None:\n",
    "        assert num_windows is None, \"num_windows must be None if starts is provided\"\n",
    "        num_windows = len(starts)\n",
    "    else:\n",
    "        if num_windows is None:\n",
    "            raise ValueError(\"num_windows must be provided if starts is not provided\")\n",
    "        starts = np.random.randint(0, len(data) - context_length - prediction_length, num_windows)\n",
    "\n",
    "    assert len(starts) == num_windows, \"starts must be a list of length num_windows\"\n",
    "    assert max(starts) < len(data) - context_length - prediction_length, (\n",
    "        \"starts must be less than the length of the data\"\n",
    "    )\n",
    "\n",
    "    full_metrics = defaultdict(lambda: np.zeros((num_windows, prediction_length // step)))\n",
    "\n",
    "    predictions = []\n",
    "    for s in tqdm(range(num_windows), desc=\"Sampling contexts\", total=num_windows):\n",
    "        start = starts[s]\n",
    "        context = data[start : start + context_length]\n",
    "        prediction = forecast(model, context, prediction_length, **kwargs)\n",
    "        for i in range(0, prediction_length, step):\n",
    "            pred = prediction[i : i + step]\n",
    "\n",
    "            gt = data[start + context_length + i : start + context_length + i + step]\n",
    "            submetrics = compute_metrics(pred, gt, include=metrics)\n",
    "            for k, v in submetrics.items():\n",
    "                full_metrics[k][s, i // step] += v\n",
    "        predictions.append(prediction)\n",
    "    mean_metrics = {k: v.mean(axis=0) for k, v in full_metrics.items()}\n",
    "    std_metrics = {k: v.std(axis=0) / np.sqrt(num_windows) for k, v in full_metrics.items()}\n",
    "    return mean_metrics, std_metrics, starts, predictions\n",
    "\n",
    "\n",
    "def plot_model_prediction(\n",
    "    model,\n",
    "    data: np.ndarray,\n",
    "    context_length: int,\n",
    "    prediction_length: int,\n",
    "    transpose: bool = False,\n",
    "    standardize: bool = True,\n",
    "    save_path: str | None = None,\n",
    "    color: str = \"red\",\n",
    "    **kwargs,\n",
    "):\n",
    "    context = data[:context_length]\n",
    "    groundtruth = data[context_length : context_length + prediction_length]\n",
    "    prediction = forecast(model, context, prediction_length, transpose, standardize, **kwargs)\n",
    "\n",
    "    total_length = context_length + prediction_length\n",
    "    context_ts = np.arange(context_length + 1)\n",
    "    pred_ts = np.arange(context_length, total_length)\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 4))\n",
    "    outer_grid = fig.add_gridspec(1, 2, width_ratios=[0.5, 0.5], wspace=0.05)\n",
    "    gs = outer_grid[1].subgridspec(3, 1, height_ratios=[1 / 3] * 3, wspace=0, hspace=0)\n",
    "    ax_3d = fig.add_subplot(outer_grid[0], projection=\"3d\")\n",
    "    ax_3d.plot(*context.T[:3], alpha=0.5, color=\"black\", label=\"Context\")\n",
    "    ax_3d.plot(*groundtruth.T[:3], linestyle=\"-\", color=\"black\", label=\"Groundtruth\")\n",
    "    ax_3d.plot(*prediction.T[:3], color=color, label=\"Prediction\")\n",
    "    ax_3d.legend(loc=\"upper right\", fontsize=8)\n",
    "    ax_3d.set_xlabel(\"$x_1$\")\n",
    "    ax_3d.set_ylabel(\"$x_2$\")\n",
    "    ax_3d.set_zlabel(\"$x_3$\")\n",
    "\n",
    "    # Make clean projection\n",
    "    ax_3d.grid(False)\n",
    "    ax_3d.set_facecolor(\"white\")\n",
    "    ax_3d.set_xticks([])\n",
    "    ax_3d.set_yticks([])\n",
    "    ax_3d.set_zticks([])\n",
    "    ax_3d.axis(\"off\")\n",
    "\n",
    "    axes_1d = [fig.add_subplot(gs[i, 0]) for i in range(3)]\n",
    "    for i, ax in enumerate(axes_1d):\n",
    "        ax.plot(\n",
    "            context_ts,\n",
    "            data[: context_length + 1, i],\n",
    "            alpha=0.5,\n",
    "            color=\"black\",\n",
    "        )\n",
    "        ax.plot(pred_ts, groundtruth[:, i], linestyle=\"-\", color=\"black\")\n",
    "        ax.plot(pred_ts, prediction[:, i], color=color)\n",
    "        ax.set_ylabel(f\"$x_{i + 1}$\")\n",
    "        ax.set_aspect(\"auto\")\n",
    "    axes_1d[-1].set_xlabel(\"Time\")\n",
    "\n",
    "    if save_path is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast_3d(\n",
    "    data: np.ndarray,\n",
    "    predictions_dict: dict[str, np.ndarray],\n",
    "    context_length: int,\n",
    "    prediction_length: int,\n",
    "    figsize: tuple[int, int] = (6, 6),\n",
    "    show_legend: bool = True,\n",
    "    legend_kwargs: dict[str, Any] = {},\n",
    "    save_path: str | None = None,\n",
    "):\n",
    "    context = data[: context_length + 1, :3]\n",
    "    groundtruth = data[context_length : context_length + prediction_length, :3]\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = plt.axes(projection=\"3d\")\n",
    "    ax._axis3don = False\n",
    "\n",
    "    # Combine all data to find min/max bounds\n",
    "    all_data = [context, groundtruth] + [pred[:, :3] for pred in predictions_dict.values()]\n",
    "    mins = np.array([d.min(axis=0) for d in all_data])\n",
    "    maxs = np.array([d.max(axis=0) for d in all_data])\n",
    "\n",
    "    xmin, ymin, zmin = np.min(mins, axis=0)\n",
    "    xmax, ymax, zmax = np.max(maxs, axis=0)\n",
    "\n",
    "    ax.xaxis.pane.set_visible(False)\n",
    "    ax.yaxis.pane.set_visible(False)\n",
    "    ax.zaxis.pane.set_visible(False)\n",
    "    ax.grid(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_zticks([])\n",
    "\n",
    "    ax.plot3D(*context.T, alpha=0.1, color=\"black\", zorder=1)\n",
    "    ax.plot3D(\n",
    "        *groundtruth.T,\n",
    "        alpha=0.8,\n",
    "        color=\"black\",\n",
    "        linestyle=\"-\",\n",
    "        zorder=2,\n",
    "        label=\"Ground Truth\",\n",
    "    )\n",
    "    for model_name, prediction in predictions_dict.items():\n",
    "        ax.plot3D(\n",
    "            *prediction[:, :3].T,\n",
    "            label=model_name,\n",
    "            zorder=10 if model_name == \"Panda\" else 1,\n",
    "        )\n",
    "    if show_legend:\n",
    "        ax.legend(**legend_kwargs)\n",
    "\n",
    "    ax.quiver(\n",
    "        xmin,\n",
    "        ymax,\n",
    "        zmin,\n",
    "        xmax - xmin,\n",
    "        0,\n",
    "        0,\n",
    "        color=\"black\",\n",
    "        arrow_length_ratio=0.05,\n",
    "        zorder=5,\n",
    "    )\n",
    "    ax.quiver(\n",
    "        xmin,\n",
    "        ymax,\n",
    "        zmin,\n",
    "        0,\n",
    "        -ymax + ymin,\n",
    "        0,\n",
    "        color=\"black\",\n",
    "        arrow_length_ratio=0.05,\n",
    "        zorder=5,\n",
    "    )\n",
    "    ax.quiver(\n",
    "        xmin,\n",
    "        ymax,\n",
    "        zmin,\n",
    "        0,\n",
    "        0,\n",
    "        zmax - zmin,\n",
    "        color=\"black\",\n",
    "        arrow_length_ratio=0.05,\n",
    "        zorder=5,\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_comparison(\n",
    "    model_metrics: dict[str, tuple[dict[str, np.ndarray], dict[str, np.ndarray]]],\n",
    "    prediction_length: int,\n",
    "    compute_metrics_time_interval: int,\n",
    "    metric_name: str = \"smape\",\n",
    "    colors: list[str] = DEFAULT_COLORS,\n",
    "    markers: list[str] = DEFAULT_MARKERS,\n",
    "    title: str | None = None,\n",
    "    figsize: tuple[float, float] = (4, 3),\n",
    "    show_legend: bool = True,\n",
    "    legend_kwargs: dict[str, Any] = {},\n",
    "    ylim: tuple[float | None, float | None] | None = None,\n",
    "    save_path: str | None = None,\n",
    "    metric_name_mapping: dict[str, str] = {\"smape\": \"sMAPE\"},\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot comparison between different models on a given metric.\n",
    "\n",
    "    Args:\n",
    "        model_metrics: Dictionary with model names as keys and tuples of (mean_metrics, std_metrics) as values\n",
    "        metric_name: Name of the metric to plot\n",
    "        prediction_length: Length of prediction\n",
    "        compute_metrics_time_interval: Time interval for computing metrics\n",
    "        save_path: Path to save the figure\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    ts = np.arange(\n",
    "        compute_metrics_time_interval,\n",
    "        prediction_length + compute_metrics_time_interval,\n",
    "        compute_metrics_time_interval,\n",
    "    )\n",
    "\n",
    "    for i, (model_name, (mean_metrics, std_metrics)) in enumerate(model_metrics.items()):\n",
    "        plt.plot(\n",
    "            ts,\n",
    "            mean_metrics[metric_name],\n",
    "            color=colors[i],\n",
    "            marker=markers[i],\n",
    "            label=model_name,\n",
    "        )\n",
    "        plt.fill_between(\n",
    "            ts,\n",
    "            mean_metrics[metric_name] - std_metrics[metric_name],\n",
    "            mean_metrics[metric_name] + std_metrics[metric_name],\n",
    "            alpha=0.1,\n",
    "            color=colors[i],\n",
    "        )\n",
    "\n",
    "    metric_name_title = metric_name.upper()\n",
    "    if metric_name in metric_name_mapping:\n",
    "        metric_name_title = metric_name_mapping[metric_name]\n",
    "\n",
    "    plt.ylabel(metric_name_title, fontweight=\"bold\")\n",
    "    plt.xlabel(\"Prediction Length\", fontweight=\"bold\")\n",
    "    if show_legend:\n",
    "        plt.legend(frameon=True, **legend_kwargs)\n",
    "    plt.xticks(ts)\n",
    "    plt.tight_layout()\n",
    "    if title is not None:\n",
    "        plt.title(title, fontweight=\"bold\")\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"train\"\n",
    "INDEX = 0\n",
    "\n",
    "fpath = f\"{base_dir}/double_pendulum_chaotic/train_and_test_split/dpc_dataset_traintest_4_200_csv/{SPLIT}/{INDEX}.csv\"\n",
    "pendulum_data = np.loadtxt(fpath)\n",
    "print(pendulum_data.shape)\n",
    "\n",
    "# data is non-stationary, subsample and detrend it\n",
    "subsampled_pendulum_data = pendulum_data[::10, -4:]\n",
    "print(subsampled_pendulum_data.shape)\n",
    "## The position of the pivot point (mostly constant)\n",
    "plt.plot(pendulum_data[:, 1], -pendulum_data[:, 0])\n",
    "\n",
    "## The position of the tip of the first pendulum\n",
    "plt.plot(pendulum_data[:, 3], -pendulum_data[:, 2])\n",
    "\n",
    "## The position of the tip of the second pendulum\n",
    "plt.plot(pendulum_data[:, 5], -pendulum_data[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "prediction_length = 128\n",
    "\n",
    "compute_metrics_time_interval = 16\n",
    "\n",
    "differenced = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_prediction = forecast(\n",
    "    pft_model,\n",
    "    subsampled_pendulum_data[:context_length],\n",
    "    prediction_length,\n",
    "    limit_prediction_length=False,\n",
    "    sliding_context=True,\n",
    "    differenced=differenced,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chronos Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_ft_prediction = forecast(\n",
    "    chronos_ft,\n",
    "    subsampled_pendulum_data[:context_length],\n",
    "    prediction_length,\n",
    "    **chronos_ft_kwargs,\n",
    "    differenced=differenced,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "start_time = 0\n",
    "## The position of the tip of the second pendulum\n",
    "plt.plot(\n",
    "    subsampled_pendulum_data[start_time : start_time + context_length, 3],\n",
    "    -subsampled_pendulum_data[start_time : start_time + context_length, 2],\n",
    "    alpha=0.1,\n",
    "    color=\"black\",\n",
    ")\n",
    "plt.plot(\n",
    "    subsampled_pendulum_data[\n",
    "        start_time + context_length : start_time + context_length + prediction_length,\n",
    "        3,\n",
    "    ],\n",
    "    -subsampled_pendulum_data[\n",
    "        start_time + context_length : start_time + context_length + prediction_length,\n",
    "        2,\n",
    "    ],\n",
    "    alpha=0.8,\n",
    "    color=\"black\",\n",
    "    linestyle=\"-\",\n",
    ")\n",
    "# get rid of the ticks\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.plot(pft_prediction[:, 3], -pft_prediction[:, 2])\n",
    "# plt.plot(chronos_ft_prediction[:, 3], -chronos_ft_prediction[:, 2])\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{fig_dir}/double_pendulum_forecasts.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rseed = 123\n",
    "num_windows_pendulum = 20\n",
    "rng = np.random.default_rng(rseed)\n",
    "pendulum_start_times = rng.choice(\n",
    "    len(subsampled_pendulum_data) - context_length - prediction_length,\n",
    "    size=num_windows_pendulum,\n",
    "    replace=False,\n",
    ")\n",
    "print(pendulum_start_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_mean_metrics, pft_std_metrics, _, pft_predictions = compute_rollout_metrics(\n",
    "    pft_model,\n",
    "    subsampled_pendulum_data,\n",
    "    context_length,\n",
    "    prediction_length=prediction_length,\n",
    "    starts=pendulum_start_times,\n",
    "    step=compute_metrics_time_interval,\n",
    "    sliding_context=True,\n",
    "    limit_prediction_length=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_ft_mean_metrics, chronos_ft_std_metrics, _, chronos_ft_predictions = compute_rollout_metrics(\n",
    "    chronos_ft,\n",
    "    subsampled_pendulum_data,\n",
    "    context_length,\n",
    "    prediction_length=prediction_length,\n",
    "    starts=pendulum_start_times,\n",
    "    step=compute_metrics_time_interval,\n",
    "    **chronos_ft_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_zs_mean_metrics, chronos_zs_std_metrics, _, chronos_zs_predictions = compute_rollout_metrics(\n",
    "    chronos_zs,\n",
    "    subsampled_pendulum_data,\n",
    "    context_length,\n",
    "    prediction_length=prediction_length,\n",
    "    starts=pendulum_start_times,\n",
    "    step=compute_metrics_time_interval,\n",
    "    **chronos_zs_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 4), sharex=True)\n",
    "plt.subplots_adjust(hspace=0.0)\n",
    "\n",
    "total_ts = np.arange(len(subsampled_pendulum_data))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.plot(\n",
    "        total_ts,\n",
    "        subsampled_pendulum_data[:, i],\n",
    "        color=\"black\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    for j, start_time in enumerate(pendulum_start_times):\n",
    "        pft_pred_ts = np.arange(start_time + context_length, start_time + context_length + prediction_length)\n",
    "        chronos_ft_context_ts = np.arange(start_time, start_time + context_length)\n",
    "        chronos_ft_pred_ts = np.arange(\n",
    "            start_time + context_length,\n",
    "            start_time + context_length + prediction_length,\n",
    "        )\n",
    "        chronos_zs_context_ts = np.arange(start_time, start_time + context_length)\n",
    "        chronos_zs_pred_ts = np.arange(\n",
    "            start_time + context_length,\n",
    "            start_time + context_length + prediction_length,\n",
    "        )\n",
    "        ax.plot(pft_pred_ts, pft_predictions[j][:, i], color=DEFAULT_COLORS[0], alpha=0.1)\n",
    "        ax.plot(\n",
    "            chronos_ft_pred_ts,\n",
    "            chronos_ft_predictions[j][:, i],\n",
    "            color=DEFAULT_COLORS[1],\n",
    "            alpha=0.1,\n",
    "        )\n",
    "        ax.plot(\n",
    "            chronos_zs_pred_ts,\n",
    "            chronos_zs_predictions[j][:, i],\n",
    "            color=DEFAULT_COLORS[2],\n",
    "            alpha=0.1,\n",
    "        )\n",
    "        # get rid of the ticks\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {\n",
    "    \"Panda\": (pft_mean_metrics, pft_std_metrics),\n",
    "    \"Chronos 20M SFT\": (chronos_ft_mean_metrics, chronos_ft_std_metrics),\n",
    "    \"Chronos 20M\": (chronos_zs_mean_metrics, chronos_zs_std_metrics),\n",
    "}\n",
    "\n",
    "plot_metric_comparison(\n",
    "    model_metrics,\n",
    "    prediction_length,\n",
    "    compute_metrics_time_interval,\n",
    "    metric_name=\"smape\",\n",
    "    ylim=(0, None),\n",
    "    save_path=f\"{fig_dir}/double_pendulum_comparison_smape.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"../outputs/double_pendulum\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "pickle.dump(model_metrics, open(os.path.join(save_dir, \"model_metrics.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenworms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = 9\n",
    "fpath = f\"{base_dir}/worm_behavior/data/worm_{INDEX}.pkl\"\n",
    "worm_data = np.load(fpath, allow_pickle=True)\n",
    "eigenworms = loadmat(f\"{base_dir}/worm_behavior/data/EigenWorms.mat\")[\"EigenWorms\"]\n",
    "\n",
    "# de-NaN the data with linear interpolation\n",
    "time_idx = np.arange(len(worm_data))\n",
    "for d in range(worm_data.shape[1]):\n",
    "    mask = np.isnan(worm_data[:, d])\n",
    "    if mask.any():\n",
    "        valid = ~mask\n",
    "        worm_data[:, d] = np.interp(time_idx, time_idx[valid], worm_data[valid, d])\n",
    "assert not np.isnan(worm_data).any()\n",
    "\n",
    "worm_data_subsampled = worm_data[2048::1]\n",
    "print(worm_data_subsampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "\n",
    "def reconstruct_worm(coeffs, eigenworms, segment_length=1.0):\n",
    "    \"\"\"\n",
    "    Reconstruct a worm from its coefficients and the eigenworms.\n",
    "\n",
    "    Args:\n",
    "        coeffs: The coefficients of the worm (n_timesteps, n_eigenworms)\n",
    "        eigenworms: The eigenworms (n_features, n_eigenworms)\n",
    "        segment_length: The length of each segment of the worm.\n",
    "\n",
    "    Returns:\n",
    "        The reconstructed worm.\n",
    "    \"\"\"\n",
    "    T, nworms = coeffs.shape\n",
    "    n_segments = eigenworms.shape[0]\n",
    "    basis = eigenworms[:, :nworms]\n",
    "    theta = coeffs @ basis.T\n",
    "\n",
    "    x = np.zeros((T, n_segments + 1))\n",
    "    y = np.zeros((T, n_segments + 1))\n",
    "    x[:, 1:] = segment_length * np.cos(theta)\n",
    "    y[:, 1:] = segment_length * np.sin(theta)\n",
    "\n",
    "    return x.cumsum(axis=1), y.cumsum(axis=1)\n",
    "\n",
    "\n",
    "def animate_worm(x, y, num_frames=200, interval=50, save_path=None):\n",
    "    \"\"\"\n",
    "    Create an animation of the worm's movement over time.\n",
    "\n",
    "    Args:\n",
    "        x: Array of x coordinates with shape (T, n_segments+1)\n",
    "        y: Array of y coordinates with shape (T, n_segments+1)\n",
    "        num_frames: Number of frames to include in the animation\n",
    "        interval: Time between frames in milliseconds\n",
    "\n",
    "    Returns:\n",
    "        HTML animation that can be displayed in the notebook\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Set consistent axis limits for the animation\n",
    "    x_min, x_max = x.min(), x.max()\n",
    "    y_min, y_max = y.min(), y.max()\n",
    "\n",
    "    # Add some padding to the limits\n",
    "    x_padding = (x_max - x_min) * 0.1\n",
    "    y_padding = (y_max - y_min) * 0.1\n",
    "\n",
    "    ax.set_xlim(x_min - x_padding, x_max + x_padding)\n",
    "    ax.set_ylim(y_min - y_padding, y_max + y_padding)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_title(\"Worm Movement\")\n",
    "\n",
    "    # Create line and fill objects\n",
    "    line = ax.plot([], [], \"b-\", lw=2)[0]\n",
    "    fill = ax.fill([], [], color=\"blue\")\n",
    "    time_text = ax.text(0.02, 0.95, \"\", transform=ax.transAxes)\n",
    "\n",
    "    # Calculate width profile - increases toward middle, decreases toward ends\n",
    "    n_points = x.shape[1]\n",
    "    width_profile = np.zeros(n_points)\n",
    "    max_width = 3  # Maximum width of the worm body\n",
    "    for i in range(n_points):\n",
    "        arg = 2 * i / (n_points - 1) - 1  # normalize to [-1, 1]\n",
    "        width_profile[i] = max_width * (1 / (1 + np.exp(-8 * (arg + 0.7))) * (1 - 1 / (1 + np.exp(-8 * (arg - 0.7)))))\n",
    "\n",
    "    def init():\n",
    "        line.set_data([], [])\n",
    "        fill[0].set_xy(np.zeros((0, 2)))\n",
    "        time_text.set_text(\"\")\n",
    "        return line, fill[0], time_text\n",
    "\n",
    "    def update(frame):\n",
    "        # Update the centerline\n",
    "        line.set_data(x[frame], y[frame])\n",
    "\n",
    "        # Calculate perpendicular vectors for width\n",
    "        dx = np.diff(x[frame])\n",
    "        dy = np.diff(y[frame])\n",
    "        # Normalize and rotate 90 degrees to get perpendicular direction\n",
    "        lengths = np.sqrt(dx**2 + dy**2)\n",
    "        nx = -dy / lengths\n",
    "        ny = dx / lengths\n",
    "\n",
    "        # Create polygon vertices for the worm body\n",
    "        vertices = []\n",
    "\n",
    "        # Top edge (add points from head to tail)\n",
    "        for i in range(n_points - 1):\n",
    "            vertices.append(\n",
    "                (\n",
    "                    x[frame][i] + width_profile[i] * nx[i],\n",
    "                    y[frame][i] + width_profile[i] * ny[i],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Bottom edge (add points from tail to head)\n",
    "        for i in range(n_points - 2, -1, -1):\n",
    "            vertices.append(\n",
    "                (\n",
    "                    x[frame][i] - width_profile[i] * nx[i],\n",
    "                    y[frame][i] - width_profile[i] * ny[i],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Update the fill\n",
    "        fill[0].set_xy(vertices)\n",
    "        time_text.set_text(f\"Frame: {frame}\")\n",
    "\n",
    "        return line, fill[0], time_text\n",
    "\n",
    "    # Use a subset of frames if there are too many\n",
    "    total_frames = min(num_frames, len(x))\n",
    "    frame_indices = np.linspace(0, len(x) - 1, total_frames, dtype=int)\n",
    "\n",
    "    anim = FuncAnimation(fig, update, frames=frame_indices, init_func=init, blit=True, interval=interval)\n",
    "    if save_path is not None:\n",
    "        anim.save(save_path, writer=\"ffmpeg\")\n",
    "    plt.close()\n",
    "    return HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create and display the animation\n",
    "# x, y = reconstruct_worm(worm_data_subsampled, eigenworms)\n",
    "# worm_animation = animate_worm(x[:1000], y[:1000], save_path=\"../figures/wormanim.mp4\")\n",
    "\n",
    "# worm_animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast Worms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "prediction_length = 128\n",
    "\n",
    "differenced = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_prediction = forecast(\n",
    "    pft_model,\n",
    "    worm_data_subsampled[:context_length],\n",
    "    prediction_length,\n",
    "    limit_prediction_length=False,\n",
    "    sliding_context=True,\n",
    "    differenced=differenced,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_ft_prediction = forecast(\n",
    "    chronos_ft,\n",
    "    worm_data_subsampled[:context_length],\n",
    "    prediction_length,\n",
    "    **chronos_ft_kwargs,\n",
    "    differenced=differenced,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast_3d(\n",
    "    worm_data_subsampled,\n",
    "    {\n",
    "        \"Panda\": pft_prediction,\n",
    "        # \"Chronos 20M SFT\": chronos_ft_prediction,\n",
    "    },\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    show_legend=False,\n",
    "    save_path=f\"{fig_dir}/worm_comparison.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "_ = plot_model_prediction(\n",
    "    pft_model,\n",
    "    worm_data_subsampled,\n",
    "    context_length=context_length,\n",
    "    prediction_length=prediction_length,\n",
    "    sliding_context=True,\n",
    "    limit_prediction_length=False,\n",
    "    differenced=differenced,\n",
    "    color=DEFAULT_COLORS[0],\n",
    ")\n",
    "_ = plot_model_prediction(\n",
    "    chronos_ft,\n",
    "    worm_data_subsampled,\n",
    "    context_length=context_length,\n",
    "    prediction_length=prediction_length,\n",
    "    **chronos_ft_kwargs,\n",
    "    differenced=differenced,\n",
    "    color=DEFAULT_COLORS[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_time_interval = 64\n",
    "prediction_length = 512\n",
    "\n",
    "worms_start_times = np.arange(0, len(worm_data_subsampled) - context_length - prediction_length, 1280)\n",
    "num_windows_worms = len(worms_start_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_mean_metrics, pft_std_metrics, _, pft_predictions = compute_rollout_metrics(\n",
    "    pft_model,\n",
    "    worm_data_subsampled,\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    starts=worms_start_times,\n",
    "    step=compute_metrics_time_interval,\n",
    "    sliding_context=True,\n",
    "    limit_prediction_length=False,\n",
    "    differenced=differenced,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_ft_mean_metrics, chronos_ft_std_metrics, _, chronos_ft_predictions = compute_rollout_metrics(\n",
    "    chronos_ft,\n",
    "    worm_data_subsampled,\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    starts=worms_start_times,\n",
    "    step=compute_metrics_time_interval,\n",
    "    differenced=differenced,\n",
    "    **chronos_ft_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_zs_mean_metrics, chronos_zs_std_metrics, _, chronos_zs_predictions = compute_rollout_metrics(\n",
    "    chronos_zs,\n",
    "    worm_data_subsampled,\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    starts=worms_start_times,\n",
    "    step=compute_metrics_time_interval,\n",
    "    differenced=differenced,\n",
    "    **chronos_zs_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {\n",
    "    \"Panda\": (pft_mean_metrics, pft_std_metrics),\n",
    "    \"Chronos 20M SFT\": (chronos_ft_mean_metrics, chronos_ft_std_metrics),\n",
    "    \"Chronos 20M\": (chronos_zs_mean_metrics, chronos_zs_std_metrics),\n",
    "}\n",
    "\n",
    "plot_metric_comparison(\n",
    "    model_metrics,\n",
    "    prediction_length,\n",
    "    compute_metrics_time_interval,\n",
    "    metric_name=\"smape\",\n",
    "    save_path=f\"{fig_dir}/worms_comparison_smape.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"../outputs/eigenworms\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "pickle.dump(model_metrics, open(os.path.join(save_dir, \"model_metrics.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electronic Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netfpath = f\"{base_dir}/electronic_circuit/Structure/Net_1.dat\"\n",
    "subdir = \"R1\"\n",
    "fname = \"ST_100_3\"\n",
    "fpath = f\"{base_dir}/electronic_circuit/{subdir}/{fname}.dat\"\n",
    "net = np.loadtxt(netfpath)\n",
    "circuit_data = np.loadtxt(fpath)\n",
    "print(net.shape, circuit_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "prediction_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_prediction = forecast(\n",
    "    pft_model,\n",
    "    circuit_data[:context_length],\n",
    "    prediction_length,\n",
    "    limit_prediction_length=False,\n",
    "    sliding_context=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_ft_prediction = forecast(\n",
    "    chronos_ft,\n",
    "    circuit_data[:context_length],\n",
    "    prediction_length,\n",
    "    **chronos_ft_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_zs_prediction = forecast(\n",
    "    chronos_zs,\n",
    "    circuit_data[:context_length],\n",
    "    prediction_length,\n",
    "    **chronos_zs_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast_3d(\n",
    "    circuit_data,\n",
    "    {\n",
    "        \"Panda\": pft_prediction,\n",
    "        \"Chronos 20M SFT\": chronos_ft_prediction,\n",
    "        \"Chronos 20M\": chronos_zs_prediction,\n",
    "    },\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    show_legend=False,\n",
    "    legend_kwargs={\"loc\": \"center right\", \"frameon\": True},\n",
    "    # save_path=f\"{fig_dir}/circuit_comparison_{subdir}_{fname}.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "_ = plot_model_prediction(\n",
    "    pft_model,\n",
    "    circuit_data,\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    sliding_context=True,\n",
    "    limit_prediction_length=False,\n",
    ")\n",
    "_ = plot_model_prediction(\n",
    "    chronos_ft,\n",
    "    circuit_data,\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    **chronos_ft_kwargs,\n",
    "    color=DEFAULT_COLORS[1],\n",
    ")\n",
    "_ = plot_model_prediction(\n",
    "    chronos_zs,\n",
    "    circuit_data,\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    **chronos_zs_kwargs,\n",
    "    color=DEFAULT_COLORS[2],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coupling Strength Scaling Law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpaths = os.listdir(f\"{base_dir}/electronic_circuit/R1\")\n",
    "ec_fpaths = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fpath in fpaths:\n",
    "    ec_fpaths[int(fpath.split(\"_\")[2][0])].append(fpath)\n",
    "for k, v in ec_fpaths.items():\n",
    "    ec_fpaths[k] = sorted(v, key=lambda x: int(x.split(\"_\")[1]))\n",
    "\n",
    "# subset the data by coupling strength\n",
    "coupling_strength_interval = 10\n",
    "ec_fpaths = {k: v[::coupling_strength_interval] for k, v in ec_fpaths.items()}\n",
    "print(ec_fpaths)\n",
    "\n",
    "coupling_strengths_lst = [\n",
    "    int(fpath.split(\"_\")[1]) for fpath in ec_fpaths[1]\n",
    "]  # Assume same coupling strength for ec splits\n",
    "print(coupling_strengths_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 8\n",
    "step = prediction_length // n_steps\n",
    "\n",
    "save_dir = \"../outputs/electronic_circuit\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_by_model = {\n",
    "    \"Panda\": {k: {m: np.zeros((n_steps, len(v))) for m in metrics} for k, v in ec_fpaths.items()},\n",
    "    \"Chronos 20M SFT\": {k: {m: np.zeros((n_steps, len(v))) for m in metrics} for k, v in ec_fpaths.items()},\n",
    "    \"Chronos 20M\": {k: {m: np.zeros((n_steps, len(v))) for m in metrics} for k, v in ec_fpaths.items()},\n",
    "}\n",
    "\n",
    "for k, v in tqdm(ec_fpaths.items()):\n",
    "    for i, fpath in tqdm(enumerate(v), desc=f\"Processing experiment {k}\", total=len(v)):\n",
    "        circuit_data = np.loadtxt(f\"{base_dir}/electronic_circuit/R1/{fpath}\")\n",
    "        pft_prediction = forecast(\n",
    "            pft_model,\n",
    "            circuit_data[:context_length],\n",
    "            prediction_length,\n",
    "            limit_prediction_length=False,\n",
    "            sliding_context=True,\n",
    "        )\n",
    "        chronos_ft_prediction = forecast(\n",
    "            chronos_ft,\n",
    "            circuit_data[:context_length],\n",
    "            prediction_length,\n",
    "            **chronos_ft_kwargs,\n",
    "        )\n",
    "        chronos_zs_prediction = forecast(\n",
    "            chronos_zs,\n",
    "            circuit_data[:context_length],\n",
    "            prediction_length,\n",
    "            **chronos_zs_kwargs,\n",
    "        )\n",
    "\n",
    "        for chunk, j in enumerate(np.arange(0, prediction_length, prediction_length // n_steps)):\n",
    "            target = circuit_data[context_length : context_length + j + step]\n",
    "\n",
    "            curr_preds_by_model = {\n",
    "                \"Panda\": pft_prediction[0 : j + step],\n",
    "                \"Chronos 20M SFT\": chronos_ft_prediction[0 : j + step],\n",
    "                \"Chronos 20M\": chronos_zs_prediction[0 : j + step],\n",
    "            }\n",
    "            for model_name, pred in curr_preds_by_model.items():\n",
    "                model_metrics = compute_metrics(pred, target, include=metrics)\n",
    "                for metric in metrics:\n",
    "                    metrics_by_model[model_name][k][metric][chunk, i] = model_metrics[metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the metrics\n",
    "for model_name in metrics_by_model.keys():\n",
    "    pickle.dump(\n",
    "        metrics_by_model[model_name],\n",
    "        open(os.path.join(save_dir, f\"{model_name}_metrics.pkl\"), \"wb\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_metrics_path_dict = {\n",
    "    \"Panda\": os.path.join(save_dir, \"Panda_metrics.pkl\"),\n",
    "    \"Chronos 20M SFT\": os.path.join(save_dir, \"Chronos 20M SFT_metrics.pkl\"),\n",
    "    \"Chronos 20M\": os.path.join(save_dir, \"Chronos 20M_metrics.pkl\"),\n",
    "}\n",
    "\n",
    "metrics_by_model = {}\n",
    "for model_name, path in saved_metrics_path_dict.items():\n",
    "    metrics_by_model[model_name] = pickle.load(open(path, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaged over experiments\n",
    "mean_metrics = defaultdict(dict)\n",
    "std_metrics = defaultdict(dict)\n",
    "\n",
    "# averaged over experiments at the middle coupling strength\n",
    "mean_metrics_middle = defaultdict(dict)\n",
    "std_metrics_middle = defaultdict(dict)\n",
    "\n",
    "for model_name, model_metrics in metrics_by_model.items():\n",
    "    for m in metrics:\n",
    "        metrics_arr = np.array([model_metrics[k][m] for k in ec_fpaths])\n",
    "        num_exp, _, num_coupling = metrics_arr.shape\n",
    "        mean_metrics[model_name][m] = np.mean(metrics_arr, axis=0)\n",
    "        std_metrics[model_name][m] = np.std(metrics_arr, axis=0) / np.sqrt(num_exp)\n",
    "        mean_metrics_middle[model_name][m] = np.mean(metrics_arr[..., num_coupling // 2], axis=0)\n",
    "        std_metrics_middle[model_name][m] = np.std(metrics_arr[..., num_coupling // 2], axis=0) / np.sqrt(num_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaged over experiments at the middle coupling strength\n",
    "model_metrics = {\n",
    "    \"Panda\": (mean_metrics_middle[\"Panda\"], std_metrics_middle[\"Panda\"]),\n",
    "    \"Chronos 20M SFT\": (\n",
    "        mean_metrics_middle[\"Chronos 20M SFT\"],\n",
    "        std_metrics_middle[\"Chronos 20M SFT\"],\n",
    "    ),\n",
    "    \"Chronos 20M\": (\n",
    "        mean_metrics_middle[\"Chronos 20M\"],\n",
    "        std_metrics_middle[\"Chronos 20M\"],\n",
    "    ),\n",
    "}\n",
    "\n",
    "plot_metric_comparison(\n",
    "    model_metrics,\n",
    "    prediction_length,\n",
    "    prediction_length // n_steps,\n",
    "    metric_name=\"smape\",\n",
    "    save_path=f\"{fig_dir}/circuit_comparison_smape_@50.pdf\",\n",
    "    legend_kwargs={\"loc\": \"upper left\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "\n",
    "metric_rollout_length_idx = -1\n",
    "\n",
    "for model_name in metrics_by_model.keys():\n",
    "    data = mean_metrics[model_name][\"smape\"][metric_rollout_length_idx]\n",
    "    std = std_metrics[model_name][\"smape\"][metric_rollout_length_idx]\n",
    "\n",
    "    assert len(data) == len(coupling_strengths_lst)\n",
    "\n",
    "    plt.plot(coupling_strengths_lst, data, label=model_name)\n",
    "    plt.fill_between(coupling_strengths_lst, data - std, data + std, alpha=0.2)\n",
    "\n",
    "plt.xlabel(\"Coupling Strength\", fontweight=\"bold\")\n",
    "plt.ylabel(\"sMAPE\", fontweight=\"bold\")\n",
    "plt.legend(loc=\"upper right\", frameon=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{fig_dir}/circuit_coupling_strength_scaling.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 6))\n",
    "# plt.title(r\"% $\\Delta$sMAPE\", fontweight=\"bold\")\n",
    "plt.title(r\"Log sMAPE Ratio\", fontweight=\"bold\")\n",
    "\n",
    "# Define the starting coupling strength and range\n",
    "start_coupling = 0\n",
    "coupling_strengths = np.array(coupling_strengths_lst)\n",
    "coupling_range = coupling_strengths[coupling_strengths >= start_coupling]\n",
    "\n",
    "pred_length_start_idx = 0\n",
    "# Extract the data for the specified coupling range\n",
    "chronos_data = metrics_by_model[\"Chronos 20M SFT\"][k][\"smape\"][:, coupling_strengths >= start_coupling]\n",
    "our_model_data = metrics_by_model[\"Panda\"][k][\"smape\"][:, coupling_strengths >= start_coupling]\n",
    "\n",
    "# Calculate percentage error over the specified range\n",
    "percentage_error = np.log(our_model_data[pred_length_start_idx:, :] / chronos_data[pred_length_start_idx:, :])\n",
    "print(percentage_error.shape)\n",
    "# Find the maximum absolute value to center the colormap at zero\n",
    "vmax = np.abs(percentage_error).max()\n",
    "\n",
    "# Transpose the data for swapping axes\n",
    "percentage_error = percentage_error.T\n",
    "\n",
    "# Flip the y-axis by using origin='upper' and adjusting the extent\n",
    "# Now prediction length is on x-axis and coupling strength is on y-axis\n",
    "plt.imshow(\n",
    "    percentage_error,\n",
    "    cmap=\"RdBu\",\n",
    "    label=f\"Type-{k}\",\n",
    "    aspect=\"auto\",\n",
    "    vmin=-vmax,\n",
    "    vmax=vmax,\n",
    "    extent=(0, percentage_error.shape[1], coupling_range[-1], coupling_range[0]),\n",
    "    origin=\"upper\",\n",
    ")\n",
    "cbar = plt.colorbar(format=\"%.1f\", shrink=0.75)\n",
    "plt.xlabel(\"Prediction Length\", fontweight=\"bold\")\n",
    "plt.xticks(\n",
    "    np.arange(n_steps - pred_length_start_idx),\n",
    "    [str(i) for i in np.arange(0, prediction_length, prediction_length // n_steps) + prediction_length // n_steps][\n",
    "        pred_length_start_idx:\n",
    "    ],\n",
    "    rotation=45,\n",
    ")\n",
    "plt.ylabel(\"Coupling Strength\", fontweight=\"bold\", labelpad=-2)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f\"{fig_dir}/circuit_coupling_scaling_heatmap_transposed.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
